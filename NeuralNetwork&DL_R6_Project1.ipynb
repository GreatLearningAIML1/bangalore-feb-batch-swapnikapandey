{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNDL_Proj 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y82BJcZvADJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pandas import read_csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Two4C0gA21B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3b9b3055-1092-4dc0-b777-efcae7e19385"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCkLr6HywR2W",
        "colab_type": "text"
      },
      "source": [
        "1. Read the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4yCkJOXBHs0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "d7dae65d-302d-4aaf-a4c5-6ec4a18f7a4c"
      },
      "source": [
        "# load dataset\n",
        "\n",
        "dataframe = read_csv(\"/content/drive/My Drive/Colab Notebooks/aiml/bank.csv\")\n",
        "dataframe.head()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGqoLyNgwZvR",
        "colab_type": "text"
      },
      "source": [
        "2. Drop the columns which are unique for all users like IDs (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W1cURg_DS0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = dataframe.drop(['CustomerId'], axis=1)\n",
        "df1 = df.drop(['RowNumber'], axis=1)\n",
        "df2 = df1.drop(['Surname'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzWcvaywFjGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "1a51bdb4-af47-4550-dc9f-94995f7c6f43"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
              "0          619    France  Female  ...               1        101348.88       1\n",
              "1          608     Spain  Female  ...               1        112542.58       0\n",
              "2          502    France  Female  ...               0        113931.57       1\n",
              "3          699    France  Female  ...               0         93826.63       0\n",
              "4          850     Spain  Female  ...               1         79084.10       0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8lcIvCIwxD7",
        "colab_type": "text"
      },
      "source": [
        "3. Distinguish the feature and target set (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DOSuGPYDtmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split into input (X) and output (Y) variables\n",
        "X = df2.iloc[:,0:10]\n",
        "Y = df2.iloc[:,10]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE2jdcoIJPKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "5c4fecd3-98ae-4343-fa95-6bdfbe308c03"
      },
      "source": [
        "X.info()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 10 columns):\n",
            "CreditScore        10000 non-null int64\n",
            "Geography          10000 non-null object\n",
            "Gender             10000 non-null object\n",
            "Age                10000 non-null int64\n",
            "Tenure             10000 non-null int64\n",
            "Balance            10000 non-null float64\n",
            "NumOfProducts      10000 non-null int64\n",
            "HasCrCard          10000 non-null int64\n",
            "IsActiveMember     10000 non-null int64\n",
            "EstimatedSalary    10000 non-null float64\n",
            "dtypes: float64(2), int64(6), object(2)\n",
            "memory usage: 781.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igyAg97NJfTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbd8e845-9ed5-44de-97aa-792850388d4a"
      },
      "source": [
        "X.iloc[:,2]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Female\n",
              "1       Female\n",
              "2       Female\n",
              "3       Female\n",
              "4       Female\n",
              "5         Male\n",
              "6         Male\n",
              "7       Female\n",
              "8         Male\n",
              "9         Male\n",
              "10        Male\n",
              "11        Male\n",
              "12      Female\n",
              "13      Female\n",
              "14      Female\n",
              "15        Male\n",
              "16        Male\n",
              "17      Female\n",
              "18        Male\n",
              "19      Female\n",
              "20        Male\n",
              "21      Female\n",
              "22      Female\n",
              "23        Male\n",
              "24      Female\n",
              "25        Male\n",
              "26        Male\n",
              "27        Male\n",
              "28      Female\n",
              "29        Male\n",
              "         ...  \n",
              "9970      Male\n",
              "9971    Female\n",
              "9972      Male\n",
              "9973      Male\n",
              "9974      Male\n",
              "9975      Male\n",
              "9976    Female\n",
              "9977    Female\n",
              "9978      Male\n",
              "9979    Female\n",
              "9980      Male\n",
              "9981      Male\n",
              "9982    Female\n",
              "9983      Male\n",
              "9984      Male\n",
              "9985      Male\n",
              "9986      Male\n",
              "9987      Male\n",
              "9988      Male\n",
              "9989      Male\n",
              "9990      Male\n",
              "9991    Female\n",
              "9992      Male\n",
              "9993      Male\n",
              "9994    Female\n",
              "9995      Male\n",
              "9996      Male\n",
              "9997    Female\n",
              "9998      Male\n",
              "9999    Female\n",
              "Name: Gender, Length: 10000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg6xO2KrEJH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "label_X_gender_encoder = LabelEncoder()\n",
        "X.iloc[:,2] = label_X_gender_encoder.fit_transform(X.iloc[:,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lvy5wKAMrrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "label_X_country_encoder = LabelEncoder()\n",
        "X.iloc[:,1] = label_X_country_encoder.fit_transform(X.iloc[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxIwt0SfMAAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa9a49ef-ebee-4fe2-ad94-204bfb564d10"
      },
      "source": [
        ""
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      CreditScore Geography  Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
            "0             619    France       0  ...          1               1        101348.88\n",
            "1             608     Spain       0  ...          0               1        112542.58\n",
            "2             502    France       0  ...          1               0        113931.57\n",
            "3             699    France       0  ...          0               0         93826.63\n",
            "4             850     Spain       0  ...          1               1         79084.10\n",
            "5             645     Spain       1  ...          1               0        149756.71\n",
            "6             822    France       1  ...          1               1         10062.80\n",
            "7             376   Germany       0  ...          1               0        119346.88\n",
            "8             501    France       1  ...          0               1         74940.50\n",
            "9             684    France       1  ...          1               1         71725.73\n",
            "10            528    France       1  ...          0               0         80181.12\n",
            "11            497     Spain       1  ...          1               0         76390.01\n",
            "12            476    France       0  ...          1               0         26260.98\n",
            "13            549    France       0  ...          0               0        190857.79\n",
            "14            635     Spain       0  ...          1               1         65951.65\n",
            "15            616   Germany       1  ...          0               1         64327.26\n",
            "16            653   Germany       1  ...          1               0          5097.67\n",
            "17            549     Spain       0  ...          1               1         14406.41\n",
            "18            587     Spain       1  ...          0               0        158684.81\n",
            "19            726    France       0  ...          1               1         54724.03\n",
            "20            732    France       1  ...          1               1        170886.17\n",
            "21            636     Spain       0  ...          1               0        138555.46\n",
            "22            510     Spain       0  ...          1               0        118913.53\n",
            "23            669    France       1  ...          0               1          8487.75\n",
            "24            846    France       0  ...          1               1        187616.16\n",
            "25            577    France       1  ...          0               1        124508.29\n",
            "26            756   Germany       1  ...          1               1        170041.95\n",
            "27            571    France       1  ...          0               0         38433.35\n",
            "28            574   Germany       0  ...          1               1        100187.43\n",
            "29            411    France       1  ...          1               1         53483.21\n",
            "...           ...       ...     ...  ...        ...             ...              ...\n",
            "9970          518    France       1  ...          1               0        119377.36\n",
            "9971          833    France       0  ...          0               0        166472.81\n",
            "9972          758    France       1  ...          1               0        171552.02\n",
            "9973          611    France       1  ...          1               1        157474.10\n",
            "9974          583    France       1  ...          1               0         13549.24\n",
            "9975          610   Germany       1  ...          1               0        196526.55\n",
            "9976          637    France       0  ...          1               0         84419.78\n",
            "9977          683    France       0  ...          1               1         24991.92\n",
            "9978          774    France       1  ...          1               0        191608.97\n",
            "9979          677    France       0  ...          0               1          2988.28\n",
            "9980          741     Spain       1  ...          0               0         99595.67\n",
            "9981          498   Germany       1  ...          1               1         53445.17\n",
            "9982          655   Germany       0  ...          1               0        115146.40\n",
            "9983          613    France       1  ...          0               0        151325.24\n",
            "9984          602   Germany       1  ...          1               1         51695.41\n",
            "9985          659    France       1  ...          1               0         96833.00\n",
            "9986          673   Germany       1  ...          0               1         34047.54\n",
            "9987          606     Spain       1  ...          1               1          1914.41\n",
            "9988          775    France       1  ...          1               0         49337.84\n",
            "9989          841     Spain       1  ...          1               1        179436.60\n",
            "9990          714   Germany       1  ...          1               0         53667.08\n",
            "9991          597    France       0  ...          1               0         69384.71\n",
            "9992          726     Spain       1  ...          1               0        195192.40\n",
            "9993          644    France       1  ...          1               0         29179.52\n",
            "9994          800    France       0  ...          0               0        167773.55\n",
            "9995          771    France       1  ...          1               0         96270.64\n",
            "9996          516    France       1  ...          1               1        101699.77\n",
            "9997          709    France       0  ...          0               1         42085.58\n",
            "9998          772   Germany       1  ...          1               0         92888.52\n",
            "9999          792    France       0  ...          1               0         38190.78\n",
            "\n",
            "[10000 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FzzrBekJpEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "e3eafdc9-a67f-466c-8846-4227a2b488db"
      },
      "source": [
        "countryhotencoder = OneHotEncoder(categorical_features = [1]) # 1 is the country column\n",
        "X = countryhotencoder.fit_transform(X).toarray()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL5986CHw8Wh",
        "colab_type": "text"
      },
      "source": [
        "4. Divide the data set into Train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvwxn8C-M1F7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training and Testing set.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRGUWCo2xEjZ",
        "colab_type": "text"
      },
      "source": [
        "5. Normalize the train and test data (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTSya58lBp0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1SganjVxKmf",
        "colab_type": "text"
      },
      "source": [
        "6. Initialize & build the model (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8zqnt0VHHtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHuS3YsIHgWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing the ANN\n",
        "classifier = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0QHNnOeOQgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This adds the input layer (by specifying input dimension) AND the first hidden layer (units)\n",
        "classifier.add(Dense(activation = 'relu', input_dim = 12, units=6, kernel_initializer='uniform'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c_GeEDsOZil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the second hidden layer\n",
        "# Notice that we do not need to specify input dim. \n",
        "classifier.add(Dense(activation = 'relu', units=6, kernel_initializer='uniform')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZYxG_SIOjMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the output layer\n",
        "# Notice that we do not need to specify input dim. \n",
        "# we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)\n",
        "# We use the sigmoid because we want probability outcomes\n",
        "classifier.add(Dense(activation = 'sigmoid', units=1, kernel_initializer='uniform')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpytfIxlxRl_",
        "colab_type": "text"
      },
      "source": [
        "7. Optimize the model (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrAQDFqlOqAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzrGTGCDOvlP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7aaa18bd-15d2-4f67-a0bc-a84c0f963442"
      },
      "source": [
        "classifier.fit(X_train, y_train, batch_size=10, epochs=100)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0901 16:38:05.779491 139798958815104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 2s 211us/step - loss: 0.4874 - acc: 0.7955\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.4308 - acc: 0.7960\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.4263 - acc: 0.7960\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.4232 - acc: 0.8005\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4199 - acc: 0.8211\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4171 - acc: 0.8235\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4154 - acc: 0.8280\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.4136 - acc: 0.8309\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4121 - acc: 0.8325\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 1s 115us/step - loss: 0.4110 - acc: 0.8305\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 1s 113us/step - loss: 0.4098 - acc: 0.8331\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.4092 - acc: 0.8334\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4078 - acc: 0.8350\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4075 - acc: 0.8341\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4065 - acc: 0.8346\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4060 - acc: 0.8335\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.4058 - acc: 0.8344\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4052 - acc: 0.8341\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4046 - acc: 0.8332\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 1s 116us/step - loss: 0.4041 - acc: 0.8351\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 1s 113us/step - loss: 0.4039 - acc: 0.8342\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4041 - acc: 0.8364\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 1s 116us/step - loss: 0.4036 - acc: 0.8347\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4039 - acc: 0.8335\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.4033 - acc: 0.8346\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.4034 - acc: 0.8332\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 1s 115us/step - loss: 0.4034 - acc: 0.8350\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4026 - acc: 0.8340\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4021 - acc: 0.8342\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 1s 114us/step - loss: 0.4027 - acc: 0.8356\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4025 - acc: 0.8352\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.4022 - acc: 0.8341\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4022 - acc: 0.8351\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 1s 115us/step - loss: 0.4015 - acc: 0.8360\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4020 - acc: 0.8339\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4017 - acc: 0.8347\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4018 - acc: 0.8351\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.4016 - acc: 0.8360\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4017 - acc: 0.8347\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4016 - acc: 0.8354\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.4014 - acc: 0.8345\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4014 - acc: 0.8357\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.4012 - acc: 0.8350\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4008 - acc: 0.8337\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4010 - acc: 0.8337\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4006 - acc: 0.8349\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 1s 113us/step - loss: 0.4009 - acc: 0.8337\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4012 - acc: 0.8347\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 1s 115us/step - loss: 0.4006 - acc: 0.8344\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.4012 - acc: 0.8352\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 1s 114us/step - loss: 0.4011 - acc: 0.8336\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.4016 - acc: 0.8352\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4010 - acc: 0.8350\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4010 - acc: 0.8345\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4006 - acc: 0.8355\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4009 - acc: 0.8337\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4010 - acc: 0.8347\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 1s 105us/step - loss: 0.4005 - acc: 0.8345\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4012 - acc: 0.8345\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.4005 - acc: 0.8352\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4012 - acc: 0.8345\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4009 - acc: 0.8339\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.4004 - acc: 0.8340\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4005 - acc: 0.8344\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4009 - acc: 0.8349\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.4007 - acc: 0.8351\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4007 - acc: 0.8341\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4006 - acc: 0.8357\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4003 - acc: 0.8354\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4007 - acc: 0.8355\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4006 - acc: 0.8357\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4005 - acc: 0.8344\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.4009 - acc: 0.8345\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4005 - acc: 0.8345\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4006 - acc: 0.8345\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 1s 109us/step - loss: 0.4003 - acc: 0.8350\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4007 - acc: 0.8356\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.4005 - acc: 0.8341\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4007 - acc: 0.8346\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.4005 - acc: 0.8336\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.4009 - acc: 0.8349\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 1s 116us/step - loss: 0.4001 - acc: 0.8354\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 1s 110us/step - loss: 0.4006 - acc: 0.8336\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 1s 107us/step - loss: 0.4011 - acc: 0.8342\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.4004 - acc: 0.8346\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.4006 - acc: 0.8341\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4004 - acc: 0.8344\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4004 - acc: 0.8355\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4005 - acc: 0.8339\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.4007 - acc: 0.8354\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.3999 - acc: 0.8350\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 1s 118us/step - loss: 0.3999 - acc: 0.8357\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.4002 - acc: 0.8361\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 1s 114us/step - loss: 0.3999 - acc: 0.8355\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 1s 111us/step - loss: 0.4002 - acc: 0.8350\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 1s 117us/step - loss: 0.4001 - acc: 0.8340\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.4005 - acc: 0.8352\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 1s 112us/step - loss: 0.4004 - acc: 0.8354\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.4001 - acc: 0.8355\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 1s 108us/step - loss: 0.4001 - acc: 0.8347\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2537d65e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lxbDYdnxWsn",
        "colab_type": "text"
      },
      "source": [
        "8. Predict the results using 0.5 as a threshold (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "298X-I97Ekp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "6cc8f178-7493-494f-f2d3-443159ee2335"
      },
      "source": [
        "y_pred = classifier.predict_classes(X_test)\n",
        "print(y_pred)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNlrmS8OxaX4",
        "colab_type": "text"
      },
      "source": [
        "2. Print the Accuracy score and confusion matrix (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPAT7AqNDvYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0896b369-9485-48c9-a330-6fc8aa5630d1"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1544   51]\n",
            " [ 265  140]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WazaalC084I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4a53771d-caee-4ee8-e1c6-4e84ea469bd2"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtjk4aRoxmkn",
        "colab_type": "text"
      },
      "source": [
        "This means that we should have about  (1544+140)=1684  correct classifications out of our total testing data size of  2000 . This means that our accuracy for this trial was  1726÷2000=84.2% , which matches the classifier's prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-RjXzHwFIsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "13c5df77-687d-44cd-9982-044e53cc8f1e"
      },
      "source": [
        "print (((cm[0][0]+cm[1][1])*100)/(cm[0][0]+cm[1][1]+cm[0][1]+cm[1][0]), '% of testing data was classified correctly')"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84.2 % of testing data was classified correctly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr_z4L7Cx4Rd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6d0d488a-fe59-4136-c21e-4f0eee144b02"
      },
      "source": [
        "classifier.evaluate(X_test,y_test)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 0s 46us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.39819700837135313, 0.842]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soyuVsvbyhE6",
        "colab_type": "text"
      },
      "source": [
        "Model accuracy 84.2%"
      ]
    }
  ]
}