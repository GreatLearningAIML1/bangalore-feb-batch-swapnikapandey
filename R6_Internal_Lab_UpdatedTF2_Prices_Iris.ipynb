{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_Internal_Lab_UpdatedTF2_Prices_Iris.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "84Q8JfvaeZZ6"
      },
      "source": [
        "## Linear Classifier in TensorFlow \n",
        "Using Low Level API in Eager Execution mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sb7Epo0VOB58"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fHpCNRv1OB5-",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mjtb-EMcm5K0",
        "colab": {}
      },
      "source": [
        "#Enable Eager Execution if using tensflow version < 2.0\n",
        "#From tensorflow v2.0 onwards, Eager Execution will be enabled by default\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DxJDmJqqOB6K"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FhllFLyKOB6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1be0302d-bb42-42de-ffb3-4c0734b3cb44"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KiObW4V4SIOz",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B4yQKMiJOB6R",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/aiml/prices.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fgkX6SEqOB6W"
      },
      "source": [
        "### Check all columns in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7K8pWsNQOB6X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6d7727e1-9975-4ab3-ed63-ebfe2e9217b9"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['date', 'symbol', 'open', 'close', 'low', 'high', 'volume'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZMCyBAu2Ukt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "34e6b217-cf90-451c-ef74-775698dc7c1d"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 851264 entries, 0 to 851263\n",
            "Data columns (total 7 columns):\n",
            "date      851264 non-null object\n",
            "symbol    851264 non-null object\n",
            "open      851264 non-null float64\n",
            "close     851264 non-null float64\n",
            "low       851264 non-null float64\n",
            "high      851264 non-null float64\n",
            "volume    851264 non-null float64\n",
            "dtypes: float64(5), object(2)\n",
            "memory usage: 45.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7dU6X7MpOB6c"
      },
      "source": [
        "### Drop columns `date` and  `symbol`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lh_6spSKOB6e",
        "colab": {}
      },
      "source": [
        "data= data.drop([\"date\",\"symbol\"], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlwbUgTwOB6i",
        "outputId": "4bdec1a4-b1ef-4acb-c12d-5cd3f9484d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high     volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
              "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
              "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
              "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
              "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3DBv3WWYOB6q"
      },
      "source": [
        "### Consider only first 1000 rows in the dataset for building feature set and target set\n",
        "Target 'Volume' has very high values. Divide 'Volume' by 1000,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_hG9rGBOB6s",
        "colab": {}
      },
      "source": [
        "data[\"volume\"]=data[\"volume\"]/1000000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSOQOCil446e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e4f3d1b-1cb6-4843-d400-4e6b15300bb0"
      },
      "source": [
        "print(data.volume)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0          2.1636\n",
            "1          2.3864\n",
            "2          2.4895\n",
            "3          2.0063\n",
            "4          1.4086\n",
            "5          1.0980\n",
            "6          0.9496\n",
            "7          0.7853\n",
            "8          1.0937\n",
            "9          1.5235\n",
            "10         1.6539\n",
            "11         0.9443\n",
            "12         0.7449\n",
            "13         0.7038\n",
            "14         0.5631\n",
            "15         0.8961\n",
            "16         0.6804\n",
            "17         0.7499\n",
            "18         0.5742\n",
            "19         0.6948\n",
            "20         0.8963\n",
            "21         0.9563\n",
            "22         0.9971\n",
            "23         1.2005\n",
            "24         1.7252\n",
            "25         1.9460\n",
            "26         1.3195\n",
            "27         0.9224\n",
            "28         1.1851\n",
            "29         0.9215\n",
            "           ...   \n",
            "851234     0.4642\n",
            "851235     3.3432\n",
            "851236     2.8241\n",
            "851237     1.2218\n",
            "851238    15.0955\n",
            "851239     2.7075\n",
            "851240     0.4582\n",
            "851241     1.2306\n",
            "851242     3.9803\n",
            "851243     6.8720\n",
            "851244     0.8112\n",
            "851245     2.5389\n",
            "851246     2.8253\n",
            "851247     0.5246\n",
            "851248     1.8885\n",
            "851249     0.4661\n",
            "851250     1.8876\n",
            "851251     0.9592\n",
            "851252     2.1117\n",
            "851253     9.1178\n",
            "851254     0.9492\n",
            "851255    11.2504\n",
            "851256     0.6462\n",
            "851257     6.4316\n",
            "851258     1.8871\n",
            "851259     0.9738\n",
            "851260     1.9381\n",
            "851261     1.7012\n",
            "851262     1.3809\n",
            "851263     0.7051\n",
            "Name: volume, Length: 851264, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEk3hLv94-N_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4ccc37ad-ed07-4ed4-ef57-75556a662632"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(851264, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dul-YI9i5TAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df = data.iloc[:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeziupmZ9oud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "4a503ae5-ed46-4eee-bb40-ef64e4b7ef93"
      },
      "source": [
        "data_df.count()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "open      1000\n",
              "close     1000\n",
              "low       1000\n",
              "high      1000\n",
              "volume    1000\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMEhDVOq-m0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "c69455ed-a76c-4621-a909-cd6628c7451d"
      },
      "source": [
        "data_df.head(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2.1636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2.3864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2.4895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2.0063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1.4086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high  volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2.1636\n",
              "1  125.239998  119.980003  119.940002  125.540001  2.3864\n",
              "2  116.379997  114.949997  114.930000  119.739998  2.4895\n",
              "3  115.480003  116.620003  113.500000  117.440002  2.0063\n",
              "4  117.010002  114.970001  114.089996  117.330002  1.4086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M3UaApqYOB6x"
      },
      "source": [
        "### Divide the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4LE4U8lTdQJq",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#X=data_df[['open','close','low','high']]\n",
        "#Y=data_df['volume']\n",
        "\n",
        "X=data_df.drop(['volume'],axis=1)\n",
        "Y=data_df['volume']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFGPHunDA1w7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oYK-aUuLbrz2"
      },
      "source": [
        "#### Convert Training and Test Data to numpy float32 arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ao-S0tQGcncz",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X_train =X_train.to_numpy('float32')\n",
        "X_test=X_test.to_numpy('float32')\n",
        "y_train=y_train.to_numpy('float32')\n",
        "y_test=y_test.to_numpy('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "im1ZegbDdKgv"
      },
      "source": [
        "### Normalize the data\n",
        "You can use Normalizer from sklearn.preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-YT6JhbKTFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "#normalized_xtrain = Normalizer().fit(X_train)\n",
        "#xtrain = normalized_xtrain.transform(X_train)\n",
        "#normalized_xtest = Normalizer().fit(X_test)\n",
        "#xtest=normalized_xtest.transform(X_test)\n",
        "x_train=normalize(np.vstack([X_train]), norm='l2', axis=1)\n",
        "x_test=normalize(np.vstack([X_test]), norm='l2', axis=1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v6vE4eYCOB62"
      },
      "source": [
        "## Building the Model in tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "297_qja4OB7A"
      },
      "source": [
        "1.Define Weights and Bias, use tf.zeros to initialize weights and Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L205qPeQOB7B",
        "colab": {}
      },
      "source": [
        "W = tf.random.normal(shape=[4,1], name=\"Weights\")\n",
        "b = tf.random.normal(shape=[1],name=\"Bias\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HgtWA-UIOB7F"
      },
      "source": [
        "2.Define a function to calculate prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JveGlx25OB7H",
        "colab": {}
      },
      "source": [
        "def fn_prediction(x,W,b):\n",
        "  y = tf.add(tf.matmul(np.array(x),W),b,name='output')\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TL1hIwf_OB7M"
      },
      "source": [
        "3.Loss (Cost) Function [Mean square error]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8VSWPiGXOB7P",
        "colab": {}
      },
      "source": [
        "def fn_loss(y, y_pred):\n",
        "  loss = tf.reduce_mean(tf.square(y-y_pred),name='Loss')\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jzG85FUlOB7U"
      },
      "source": [
        "4.Function to train the Model\n",
        "\n",
        "1.   Record all the mathematical steps to calculate Loss\n",
        "2.   Calculate Gradients of Loss w.r.t weights and bias\n",
        "3.   Update Weights and Bias based on gradients and learning rate to minimize loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xSypb_u8OB7e"
      },
      "source": [
        "## Train the model for 100 epochs \n",
        "1. Observe the training loss at every iteration\n",
        "2. Observe Train loss at every 5th iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVvgj7eQOB7f",
        "colab": {}
      },
      "source": [
        "def fn_train(x,y, W,b,learn_rate):\n",
        "  with tf.GradientTape() as t:\n",
        "    t.watch([W,b])\n",
        "    y_pred=fn_prediction(x_train,W,b)\n",
        "    loss=fn_loss(y,y_pred)\n",
        "    dc_dw,dc_db=t.gradient(loss,[W,b])\n",
        "    W=W-learn_rate*dc_dw\n",
        "    b=b-learn_rate*dc_db\n",
        "    return W,b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DOL2ncA1OB7q"
      },
      "source": [
        "### Get the shapes and values of W and b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGvtyTeuOB7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2708bab-e6af-4e6a-9670-6eeeee6a52d3"
      },
      "source": [
        "for i in range(100):\n",
        "  W,b = fn_train(x_train, y_train, W,b,0.01)\n",
        "  print('W at:',i,'is',W)\n",
        "  print('b at:',i,'is',b)\n",
        "  y_pred=fn_prediction(X_train, W,b)\n",
        "  train_loss=fn_loss(y_train,y_pred)\n",
        "  if i%5==0:\n",
        "    print('training loss at step:',i,'is',train_loss)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W at: 0 is tf.Tensor(\n",
            "[[-1.4521364 ]\n",
            " [-1.1101875 ]\n",
            " [ 0.73828405]\n",
            " [ 1.8384469 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 0 is tf.Tensor([-0.22149089], shape=(1,), dtype=float32)\n",
            "training loss at step: 0 is tf.Tensor(215.06105, shape=(), dtype=float32)\n",
            "W at: 1 is tf.Tensor(\n",
            "[[-1.3949246]\n",
            " [-1.0527694]\n",
            " [ 0.7949108]\n",
            " [ 1.8963537]], shape=(4, 1), dtype=float32)\n",
            "b at: 1 is tf.Tensor([-0.10690248], shape=(1,), dtype=float32)\n",
            "W at: 2 is tf.Tensor(\n",
            "[[-1.3400012 ]\n",
            " [-0.99764794]\n",
            " [ 0.8492725 ]\n",
            " [ 1.9519444 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 2 is tf.Tensor([0.00310251], shape=(1,), dtype=float32)\n",
            "W at: 3 is tf.Tensor(\n",
            "[[-1.2872747 ]\n",
            " [-0.94473124]\n",
            " [ 0.9014598 ]\n",
            " [ 2.0053115 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 3 is tf.Tensor([0.10870743], shape=(1,), dtype=float32)\n",
            "W at: 4 is tf.Tensor(\n",
            "[[-1.2366571 ]\n",
            " [-0.89393115]\n",
            " [ 0.9515597 ]\n",
            " [ 2.0565438 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 4 is tf.Tensor([0.21008825], shape=(1,), dtype=float32)\n",
            "W at: 5 is tf.Tensor(\n",
            "[[-1.1880642 ]\n",
            " [-0.84516305]\n",
            " [ 0.99965566]\n",
            " [ 2.105727  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 5 is tf.Tensor([0.30741394], shape=(1,), dtype=float32)\n",
            "training loss at step: 5 is tf.Tensor(8766.644, shape=(), dtype=float32)\n",
            "W at: 6 is tf.Tensor(\n",
            "[[-1.141415 ]\n",
            " [-0.7983456]\n",
            " [ 1.0458279]\n",
            " [ 2.152943 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 6 is tf.Tensor([0.40084672], shape=(1,), dtype=float32)\n",
            "W at: 7 is tf.Tensor(\n",
            "[[-1.0966316 ]\n",
            " [-0.75340086]\n",
            " [ 1.0901532 ]\n",
            " [ 2.19827   ]], shape=(4, 1), dtype=float32)\n",
            "b at: 7 is tf.Tensor([0.49054226], shape=(1,), dtype=float32)\n",
            "W at: 8 is tf.Tensor(\n",
            "[[-1.0536395 ]\n",
            " [-0.71025383]\n",
            " [ 1.1327056 ]\n",
            " [ 2.2417843 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 8 is tf.Tensor([0.5766501], shape=(1,), dtype=float32)\n",
            "W at: 9 is tf.Tensor(\n",
            "[[-1.0123671 ]\n",
            " [-0.66883266]\n",
            " [ 1.1735559 ]\n",
            " [ 2.2835581 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 9 is tf.Tensor([0.6593137], shape=(1,), dtype=float32)\n",
            "W at: 10 is tf.Tensor(\n",
            "[[-0.97274554]\n",
            " [-0.6290683 ]\n",
            " [ 1.2127723 ]\n",
            " [ 2.3236609 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 10 is tf.Tensor([0.7386708], shape=(1,), dtype=float32)\n",
            "training loss at step: 10 is tf.Tensor(29080.467, shape=(), dtype=float32)\n",
            "W at: 11 is tf.Tensor(\n",
            "[[-0.9347088 ]\n",
            " [-0.59089446]\n",
            " [ 1.25042   ]\n",
            " [ 2.3621595 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 11 is tf.Tensor([0.8148538], shape=(1,), dtype=float32)\n",
            "W at: 12 is tf.Tensor(\n",
            "[[-0.8981934 ]\n",
            " [-0.55424756]\n",
            " [ 1.2865618 ]\n",
            " [ 2.3991182 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 12 is tf.Tensor([0.8879895], shape=(1,), dtype=float32)\n",
            "W at: 13 is tf.Tensor(\n",
            "[[-0.8631386]\n",
            " [-0.5190665]\n",
            " [ 1.3212581]\n",
            " [ 2.4345987]], shape=(4, 1), dtype=float32)\n",
            "b at: 13 is tf.Tensor([0.95819986], shape=(1,), dtype=float32)\n",
            "W at: 14 is tf.Tensor(\n",
            "[[-0.82948595]\n",
            " [-0.48529267]\n",
            " [ 1.3545665 ]\n",
            " [ 2.4686599 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 14 is tf.Tensor([1.0256019], shape=(1,), dtype=float32)\n",
            "W at: 15 is tf.Tensor(\n",
            "[[-0.79717934]\n",
            " [-0.45286974]\n",
            " [ 1.3865426 ]\n",
            " [ 2.5013587 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 15 is tf.Tensor([1.0903078], shape=(1,), dtype=float32)\n",
            "training loss at step: 15 is tf.Tensor(54513.555, shape=(), dtype=float32)\n",
            "W at: 16 is tf.Tensor(\n",
            "[[-0.76616496]\n",
            " [-0.4217437 ]\n",
            " [ 1.4172397 ]\n",
            " [ 2.5327497 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 16 is tf.Tensor([1.1524256], shape=(1,), dtype=float32)\n",
            "W at: 17 is tf.Tensor(\n",
            "[[-0.7363911 ]\n",
            " [-0.39186266]\n",
            " [ 1.4467089 ]\n",
            " [ 2.562885  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 17 is tf.Tensor([1.2120588], shape=(1,), dtype=float32)\n",
            "W at: 18 is tf.Tensor(\n",
            "[[-0.7078082 ]\n",
            " [-0.36317685]\n",
            " [ 1.4749994 ]\n",
            " [ 2.591815  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 18 is tf.Tensor([1.2693067], shape=(1,), dtype=float32)\n",
            "W at: 19 is tf.Tensor(\n",
            "[[-0.68036854]\n",
            " [-0.33563846]\n",
            " [ 1.5021584 ]\n",
            " [ 2.6195877 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 19 is tf.Tensor([1.3242648], shape=(1,), dtype=float32)\n",
            "W at: 20 is tf.Tensor(\n",
            "[[-0.6540264 ]\n",
            " [-0.30920157]\n",
            " [ 1.528231  ]\n",
            " [ 2.6462495 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 20 is tf.Tensor([1.3770245], shape=(1,), dtype=float32)\n",
            "training loss at step: 20 is tf.Tensor(81148.02, shape=(), dtype=float32)\n",
            "W at: 21 is tf.Tensor(\n",
            "[[-0.6287379 ]\n",
            " [-0.28382215]\n",
            " [ 1.5532608 ]\n",
            " [ 2.671845  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 21 is tf.Tensor([1.4276739], shape=(1,), dtype=float32)\n",
            "W at: 22 is tf.Tensor(\n",
            "[[-0.60446095]\n",
            " [-0.2594579 ]\n",
            " [ 1.5772895 ]\n",
            " [ 2.6964166 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 22 is tf.Tensor([1.4762975], shape=(1,), dtype=float32)\n",
            "W at: 23 is tf.Tensor(\n",
            "[[-0.581155  ]\n",
            " [-0.23606816]\n",
            " [ 1.6003569 ]\n",
            " [ 2.7200053 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 23 is tf.Tensor([1.5229762], shape=(1,), dtype=float32)\n",
            "W at: 24 is tf.Tensor(\n",
            "[[-0.55878127]\n",
            " [-0.213614  ]\n",
            " [ 1.6225017 ]\n",
            " [ 2.7426505 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 24 is tf.Tensor([1.5677876], shape=(1,), dtype=float32)\n",
            "W at: 25 is tf.Tensor(\n",
            "[[-0.53730243]\n",
            " [-0.192058  ]\n",
            " [ 1.6437608 ]\n",
            " [ 2.76439   ]], shape=(4, 1), dtype=float32)\n",
            "b at: 25 is tf.Tensor([1.6108068], shape=(1,), dtype=float32)\n",
            "training loss at step: 25 is tf.Tensor(106785.664, shape=(), dtype=float32)\n",
            "W at: 26 is tf.Tensor(\n",
            "[[-0.51668274]\n",
            " [-0.17136422]\n",
            " [ 1.6641695 ]\n",
            " [ 2.7852597 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 26 is tf.Tensor([1.6521052], shape=(1,), dtype=float32)\n",
            "W at: 27 is tf.Tensor(\n",
            "[[-0.4968878 ]\n",
            " [-0.15149817]\n",
            " [ 1.683762  ]\n",
            " [ 2.8052948 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 27 is tf.Tensor([1.6917517], shape=(1,), dtype=float32)\n",
            "W at: 28 is tf.Tensor(\n",
            "[[-0.47788462]\n",
            " [-0.13242675]\n",
            " [ 1.7025707 ]\n",
            " [ 2.8245285 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 28 is tf.Tensor([1.7298124], shape=(1,), dtype=float32)\n",
            "W at: 29 is tf.Tensor(\n",
            "[[-0.45964152]\n",
            " [-0.11411818]\n",
            " [ 1.7206271 ]\n",
            " [ 2.8429928 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 29 is tf.Tensor([1.7663506], shape=(1,), dtype=float32)\n",
            "W at: 30 is tf.Tensor(\n",
            "[[-0.44212812]\n",
            " [-0.09654194]\n",
            " [ 1.7379613 ]\n",
            " [ 2.8607185 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 30 is tf.Tensor([1.8014275], shape=(1,), dtype=float32)\n",
            "training loss at step: 30 is tf.Tensor(130296.516, shape=(), dtype=float32)\n",
            "W at: 31 is tf.Tensor(\n",
            "[[-0.42531523]\n",
            " [-0.07966874]\n",
            " [ 1.7546021 ]\n",
            " [ 2.8777351 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 31 is tf.Tensor([1.8351012], shape=(1,), dtype=float32)\n",
            "W at: 32 is tf.Tensor(\n",
            "[[-0.40917483]\n",
            " [-0.06347045]\n",
            " [ 1.7705773 ]\n",
            " [ 2.894071  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 32 is tf.Tensor([1.8674281], shape=(1,), dtype=float32)\n",
            "W at: 33 is tf.Tensor(\n",
            "[[-0.39368   ]\n",
            " [-0.04792007]\n",
            " [ 1.7859136 ]\n",
            " [ 2.9097538 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 33 is tf.Tensor([1.8984618], shape=(1,), dtype=float32)\n",
            "W at: 34 is tf.Tensor(\n",
            "[[-0.37880495]\n",
            " [-0.03299171]\n",
            " [ 1.8006364 ]\n",
            " [ 2.9248092 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 34 is tf.Tensor([1.9282544], shape=(1,), dtype=float32)\n",
            "W at: 35 is tf.Tensor(\n",
            "[[-0.36452487]\n",
            " [-0.01866047]\n",
            " [ 1.8147703 ]\n",
            " [ 2.9392624 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 35 is tf.Tensor([1.9568552], shape=(1,), dtype=float32)\n",
            "training loss at step: 35 is tf.Tensor(151199.62, shape=(), dtype=float32)\n",
            "W at: 36 is tf.Tensor(\n",
            "[[-0.35081595]\n",
            " [-0.00490248]\n",
            " [ 1.8283389 ]\n",
            " [ 2.9531374 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 36 is tf.Tensor([1.984312], shape=(1,), dtype=float32)\n",
            "W at: 37 is tf.Tensor(\n",
            "[[-0.33765537]\n",
            " [ 0.00830521]\n",
            " [ 1.8413647 ]\n",
            " [ 2.9664574 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 37 is tf.Tensor([2.0106707], shape=(1,), dtype=float32)\n",
            "W at: 38 is tf.Tensor(\n",
            "[[-0.32502118]\n",
            " [ 0.0209846 ]\n",
            " [ 1.8538696 ]\n",
            " [ 2.9792445 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 38 is tf.Tensor([2.035975], shape=(1,), dtype=float32)\n",
            "W at: 39 is tf.Tensor(\n",
            "[[-0.31289235]\n",
            " [ 0.03315681]\n",
            " [ 1.8658742 ]\n",
            " [ 2.9915202 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 39 is tf.Tensor([2.0602672], shape=(1,), dtype=float32)\n",
            "W at: 40 is tf.Tensor(\n",
            "[[-0.30124864]\n",
            " [ 0.04484215]\n",
            " [ 1.8773986 ]\n",
            " [ 3.003305  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 40 is tf.Tensor([2.0835876], shape=(1,), dtype=float32)\n",
            "training loss at step: 40 is tf.Tensor(169395.64, shape=(), dtype=float32)\n",
            "W at: 41 is tf.Tensor(\n",
            "[[-0.29007065]\n",
            " [ 0.05606007]\n",
            " [ 1.8884622 ]\n",
            " [ 3.0146182 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 41 is tf.Tensor([2.1059754], shape=(1,), dtype=float32)\n",
            "W at: 42 is tf.Tensor(\n",
            "[[-0.27933976]\n",
            " [ 0.06682929]\n",
            " [ 1.8990831 ]\n",
            " [ 3.0254788 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 42 is tf.Tensor([2.1274676], shape=(1,), dtype=float32)\n",
            "W at: 43 is tf.Tensor(\n",
            "[[-0.26903808]\n",
            " [ 0.07716773]\n",
            " [ 1.9092793 ]\n",
            " [ 3.0359051 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 43 is tf.Tensor([2.1481001], shape=(1,), dtype=float32)\n",
            "W at: 44 is tf.Tensor(\n",
            "[[-0.25914845]\n",
            " [ 0.08709265]\n",
            " [ 1.9190677 ]\n",
            " [ 3.0459144 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 44 is tf.Tensor([2.1679075], shape=(1,), dtype=float32)\n",
            "W at: 45 is tf.Tensor(\n",
            "[[-0.24965438]\n",
            " [ 0.09662057]\n",
            " [ 1.9284645 ]\n",
            " [ 3.0555234 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 45 is tf.Tensor([2.1869226], shape=(1,), dtype=float32)\n",
            "training loss at step: 45 is tf.Tensor(184998.23, shape=(), dtype=float32)\n",
            "W at: 46 is tf.Tensor(\n",
            "[[-0.24054006]\n",
            " [ 0.10576738]\n",
            " [ 1.9374855 ]\n",
            " [ 3.064748  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 46 is tf.Tensor([2.2051768], shape=(1,), dtype=float32)\n",
            "W at: 47 is tf.Tensor(\n",
            "[[-0.23179027]\n",
            " [ 0.11454833]\n",
            " [ 1.9461455 ]\n",
            " [ 3.0736036 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 47 is tf.Tensor([2.222701], shape=(1,), dtype=float32)\n",
            "W at: 48 is tf.Tensor(\n",
            "[[-0.22339046]\n",
            " [ 0.12297803]\n",
            " [ 1.9544593 ]\n",
            " [ 3.082105  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 48 is tf.Tensor([2.2395244], shape=(1,), dtype=float32)\n",
            "W at: 49 is tf.Tensor(\n",
            "[[-0.21532662]\n",
            " [ 0.13107055]\n",
            " [ 1.9624405 ]\n",
            " [ 3.0902662 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 49 is tf.Tensor([2.2556748], shape=(1,), dtype=float32)\n",
            "W at: 50 is tf.Tensor(\n",
            "[[-0.20758532]\n",
            " [ 0.13883938]\n",
            " [ 1.9701024 ]\n",
            " [ 3.0981011 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 50 is tf.Tensor([2.2711792], shape=(1,), dtype=float32)\n",
            "training loss at step: 50 is tf.Tensor(198229.48, shape=(), dtype=float32)\n",
            "W at: 51 is tf.Tensor(\n",
            "[[-0.20015365]\n",
            " [ 0.14629745]\n",
            " [ 1.9774579 ]\n",
            " [ 3.1056225 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 51 is tf.Tensor([2.2860634], shape=(1,), dtype=float32)\n",
            "W at: 52 is tf.Tensor(\n",
            "[[-0.19301923]\n",
            " [ 0.15345721]\n",
            " [ 1.9845191 ]\n",
            " [ 3.112843  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 52 is tf.Tensor([2.3003523], shape=(1,), dtype=float32)\n",
            "W at: 53 is tf.Tensor(\n",
            "[[-0.18617016]\n",
            " [ 0.16033056]\n",
            " [ 1.991298  ]\n",
            " [ 3.1197748 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 53 is tf.Tensor([2.3140697], shape=(1,), dtype=float32)\n",
            "W at: 54 is tf.Tensor(\n",
            "[[-0.17959504]\n",
            " [ 0.16692899]\n",
            " [ 1.9978057 ]\n",
            " [ 3.1264293 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 54 is tf.Tensor([2.3272383], shape=(1,), dtype=float32)\n",
            "W at: 55 is tf.Tensor(\n",
            "[[-0.17328289]\n",
            " [ 0.17326348]\n",
            " [ 2.004053  ]\n",
            " [ 3.1328175 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 55 is tf.Tensor([2.3398802], shape=(1,), dtype=float32)\n",
            "training loss at step: 55 is tf.Tensor(209356.45, shape=(), dtype=float32)\n",
            "W at: 56 is tf.Tensor(\n",
            "[[-0.16722322]\n",
            " [ 0.17934458]\n",
            " [ 2.0100505 ]\n",
            " [ 3.1389503 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 56 is tf.Tensor([2.3520164], shape=(1,), dtype=float32)\n",
            "W at: 57 is tf.Tensor(\n",
            "[[-0.1614059 ]\n",
            " [ 0.18518245]\n",
            " [ 2.015808  ]\n",
            " [ 3.1448379 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 57 is tf.Tensor([2.3636672], shape=(1,), dtype=float32)\n",
            "W at: 58 is tf.Tensor(\n",
            "[[-0.15582126]\n",
            " [ 0.19078681]\n",
            " [ 2.0213354 ]\n",
            " [ 3.1504898 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 58 is tf.Tensor([2.374852], shape=(1,), dtype=float32)\n",
            "W at: 59 is tf.Tensor(\n",
            "[[-0.15045999]\n",
            " [ 0.19616699]\n",
            " [ 2.0266416 ]\n",
            " [ 3.1559157 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 59 is tf.Tensor([2.3855894], shape=(1,), dtype=float32)\n",
            "W at: 60 is tf.Tensor(\n",
            "[[-0.14531316]\n",
            " [ 0.20133196]\n",
            " [ 2.0317357 ]\n",
            " [ 3.1611245 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 60 is tf.Tensor([2.3958974], shape=(1,), dtype=float32)\n",
            "training loss at step: 60 is tf.Tensor(218654.25, shape=(), dtype=float32)\n",
            "W at: 61 is tf.Tensor(\n",
            "[[-0.14037217]\n",
            " [ 0.20629033]\n",
            " [ 2.0366259 ]\n",
            " [ 3.1661248 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 61 is tf.Tensor([2.405793], shape=(1,), dtype=float32)\n",
            "W at: 62 is tf.Tensor(\n",
            "[[-0.13562882]\n",
            " [ 0.21105038]\n",
            " [ 2.0413206 ]\n",
            " [ 3.1709251 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 62 is tf.Tensor([2.4152927], shape=(1,), dtype=float32)\n",
            "W at: 63 is tf.Tensor(\n",
            "[[-0.13107517]\n",
            " [ 0.21562001]\n",
            " [ 2.0458274 ]\n",
            " [ 3.1755335 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 63 is tf.Tensor([2.4244125], shape=(1,), dtype=float32)\n",
            "W at: 64 is tf.Tensor(\n",
            "[[-0.12670365]\n",
            " [ 0.22000685]\n",
            " [ 2.050154  ]\n",
            " [ 3.1799576 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 64 is tf.Tensor([2.4331675], shape=(1,), dtype=float32)\n",
            "W at: 65 is tf.Tensor(\n",
            "[[-0.12250698]\n",
            " [ 0.22421823]\n",
            " [ 2.0543075 ]\n",
            " [ 3.1842048 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 65 is tf.Tensor([2.4415722], shape=(1,), dtype=float32)\n",
            "training loss at step: 65 is tf.Tensor(226385.08, shape=(), dtype=float32)\n",
            "W at: 66 is tf.Tensor(\n",
            "[[-0.11847815]\n",
            " [ 0.22826116]\n",
            " [ 2.058295  ]\n",
            " [ 3.188282  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 66 is tf.Tensor([2.4496408], shape=(1,), dtype=float32)\n",
            "W at: 67 is tf.Tensor(\n",
            "[[-0.11461046]\n",
            " [ 0.23214236]\n",
            " [ 2.062123  ]\n",
            " [ 3.1921961 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 67 is tf.Tensor([2.4573867], shape=(1,), dtype=float32)\n",
            "W at: 68 is tf.Tensor(\n",
            "[[-0.11089746]\n",
            " [ 0.2358683 ]\n",
            " [ 2.0657978 ]\n",
            " [ 3.1959536 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 68 is tf.Tensor([2.4648228], shape=(1,), dtype=float32)\n",
            "W at: 69 is tf.Tensor(\n",
            "[[-0.10733296]\n",
            " [ 0.23944521]\n",
            " [ 2.0693257 ]\n",
            " [ 3.1995609 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 69 is tf.Tensor([2.4719615], shape=(1,), dtype=float32)\n",
            "W at: 70 is tf.Tensor(\n",
            "[[-0.10391103]\n",
            " [ 0.24287903]\n",
            " [ 2.0727124 ]\n",
            " [ 3.203024  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 70 is tf.Tensor([2.4788146], shape=(1,), dtype=float32)\n",
            "training loss at step: 70 is tf.Tensor(232788.17, shape=(), dtype=float32)\n",
            "W at: 71 is tf.Tensor(\n",
            "[[-0.10062595]\n",
            " [ 0.24617551]\n",
            " [ 2.0759637 ]\n",
            " [ 3.2063484 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 71 is tf.Tensor([2.4853935], shape=(1,), dtype=float32)\n",
            "W at: 72 is tf.Tensor(\n",
            "[[-0.09747227]\n",
            " [ 0.24934013]\n",
            " [ 2.0790849 ]\n",
            " [ 3.20954   ]], shape=(4, 1), dtype=float32)\n",
            "b at: 72 is tf.Tensor([2.4917095], shape=(1,), dtype=float32)\n",
            "W at: 73 is tf.Tensor(\n",
            "[[-0.09444472]\n",
            " [ 0.25237817]\n",
            " [ 2.0820813 ]\n",
            " [ 3.2126036 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 73 is tf.Tensor([2.4977727], shape=(1,), dtype=float32)\n",
            "W at: 74 is tf.Tensor(\n",
            "[[-0.09153826]\n",
            " [ 0.25529468]\n",
            " [ 2.0849578 ]\n",
            " [ 3.2155447 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 74 is tf.Tensor([2.5035934], shape=(1,), dtype=float32)\n",
            "W at: 75 is tf.Tensor(\n",
            "[[-0.08874804]\n",
            " [ 0.25809452]\n",
            " [ 2.0877194 ]\n",
            " [ 3.2183683 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 75 is tf.Tensor([2.5091813], shape=(1,), dtype=float32)\n",
            "training loss at step: 75 is tf.Tensor(238075.23, shape=(), dtype=float32)\n",
            "W at: 76 is tf.Tensor(\n",
            "[[-0.08606941]\n",
            " [ 0.26078236]\n",
            " [ 2.0903704 ]\n",
            " [ 3.2210789 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 76 is tf.Tensor([2.5145457], shape=(1,), dtype=float32)\n",
            "W at: 77 is tf.Tensor(\n",
            "[[-0.0834979 ]\n",
            " [ 0.26336268]\n",
            " [ 2.0929155 ]\n",
            " [ 3.223681  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 77 is tf.Tensor([2.5196955], shape=(1,), dtype=float32)\n",
            "W at: 78 is tf.Tensor(\n",
            "[[-0.08102925]\n",
            " [ 0.2658398 ]\n",
            " [ 2.0953588 ]\n",
            " [ 3.2261791 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 78 is tf.Tensor([2.5246394], shape=(1,), dtype=float32)\n",
            "W at: 79 is tf.Tensor(\n",
            "[[-0.07865933]\n",
            " [ 0.2682178 ]\n",
            " [ 2.0977044 ]\n",
            " [ 3.2285771 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 79 is tf.Tensor([2.5293853], shape=(1,), dtype=float32)\n",
            "W at: 80 is tf.Tensor(\n",
            "[[-0.07638419]\n",
            " [ 0.2705007 ]\n",
            " [ 2.099956  ]\n",
            " [ 3.2308793 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 80 is tf.Tensor([2.5339415], shape=(1,), dtype=float32)\n",
            "training loss at step: 80 is tf.Tensor(242430.16, shape=(), dtype=float32)\n",
            "W at: 81 is tf.Tensor(\n",
            "[[-0.07420003]\n",
            " [ 0.27269226]\n",
            " [ 2.1021178 ]\n",
            " [ 3.2330894 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 81 is tf.Tensor([2.5383155], shape=(1,), dtype=float32)\n",
            "W at: 82 is tf.Tensor(\n",
            "[[-0.07210323]\n",
            " [ 0.27479616]\n",
            " [ 2.104193  ]\n",
            " [ 3.2352111 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 82 is tf.Tensor([2.5425146], shape=(1,), dtype=float32)\n",
            "W at: 83 is tf.Tensor(\n",
            "[[-0.07009029]\n",
            " [ 0.27681592]\n",
            " [ 2.1061852 ]\n",
            " [ 3.237248  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 83 is tf.Tensor([2.5465457], shape=(1,), dtype=float32)\n",
            "W at: 84 is tf.Tensor(\n",
            "[[-0.06815784]\n",
            " [ 0.27875486]\n",
            " [ 2.1080978 ]\n",
            " [ 3.2392032 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 84 is tf.Tensor([2.5504155], shape=(1,), dtype=float32)\n",
            "W at: 85 is tf.Tensor(\n",
            "[[-0.06630269]\n",
            " [ 0.28061625]\n",
            " [ 2.1099339 ]\n",
            " [ 3.2410803 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 85 is tf.Tensor([2.5541306], shape=(1,), dtype=float32)\n",
            "training loss at step: 85 is tf.Tensor(246010.33, shape=(), dtype=float32)\n",
            "W at: 86 is tf.Tensor(\n",
            "[[-0.06452172]\n",
            " [ 0.28240317]\n",
            " [ 2.1116965 ]\n",
            " [ 3.2428823 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 86 is tf.Tensor([2.557697], shape=(1,), dtype=float32)\n",
            "W at: 87 is tf.Tensor(\n",
            "[[-0.06281198]\n",
            " [ 0.28411862]\n",
            " [ 2.1133885 ]\n",
            " [ 3.2446122 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 87 is tf.Tensor([2.5611207], shape=(1,), dtype=float32)\n",
            "W at: 88 is tf.Tensor(\n",
            "[[-0.06117061]\n",
            " [ 0.28576544]\n",
            " [ 2.115013  ]\n",
            " [ 3.246273  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 88 is tf.Tensor([2.5644076], shape=(1,), dtype=float32)\n",
            "W at: 89 is tf.Tensor(\n",
            "[[-0.05959488]\n",
            " [ 0.2873464 ]\n",
            " [ 2.1165724 ]\n",
            " [ 3.2478673 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 89 is tf.Tensor([2.567563], shape=(1,), dtype=float32)\n",
            "W at: 90 is tf.Tensor(\n",
            "[[-0.05808217]\n",
            " [ 0.2888641 ]\n",
            " [ 2.1180694 ]\n",
            " [ 3.2493978 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 90 is tf.Tensor([2.5705922], shape=(1,), dtype=float32)\n",
            "training loss at step: 90 is tf.Tensor(248948.94, shape=(), dtype=float32)\n",
            "W at: 91 is tf.Tensor(\n",
            "[[-0.05662996]\n",
            " [ 0.2903211 ]\n",
            " [ 2.1195066 ]\n",
            " [ 3.2508671 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 91 is tf.Tensor([2.5735002], shape=(1,), dtype=float32)\n",
            "W at: 92 is tf.Tensor(\n",
            "[[-0.05523582]\n",
            " [ 0.29171982]\n",
            " [ 2.1208863 ]\n",
            " [ 3.2522776 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 92 is tf.Tensor([2.5762918], shape=(1,), dtype=float32)\n",
            "W at: 93 is tf.Tensor(\n",
            "[[-0.05389743]\n",
            " [ 0.29306257]\n",
            " [ 2.1222107 ]\n",
            " [ 3.2536316 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 93 is tf.Tensor([2.5789719], shape=(1,), dtype=float32)\n",
            "W at: 94 is tf.Tensor(\n",
            "[[-0.05261256]\n",
            " [ 0.2943516 ]\n",
            " [ 2.1234822 ]\n",
            " [ 3.2549314 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 94 is tf.Tensor([2.5815446], shape=(1,), dtype=float32)\n",
            "W at: 95 is tf.Tensor(\n",
            "[[-0.05137907]\n",
            " [ 0.2955891 ]\n",
            " [ 2.124703  ]\n",
            " [ 3.2561793 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 95 is tf.Tensor([2.5840147], shape=(1,), dtype=float32)\n",
            "training loss at step: 95 is tf.Tensor(251357.9, shape=(), dtype=float32)\n",
            "W at: 96 is tf.Tensor(\n",
            "[[-0.05019491]\n",
            " [ 0.29677707]\n",
            " [ 2.1258748 ]\n",
            " [ 3.2573774 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 96 is tf.Tensor([2.5863857], shape=(1,), dtype=float32)\n",
            "W at: 97 is tf.Tensor(\n",
            "[[-0.0490581 ]\n",
            " [ 0.29791752]\n",
            " [ 2.1269999 ]\n",
            " [ 3.2585275 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 97 is tf.Tensor([2.588662], shape=(1,), dtype=float32)\n",
            "W at: 98 is tf.Tensor(\n",
            "[[-0.04796675]\n",
            " [ 0.29901233]\n",
            " [ 2.12808   ]\n",
            " [ 3.2596316 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 98 is tf.Tensor([2.590847], shape=(1,), dtype=float32)\n",
            "W at: 99 is tf.Tensor(\n",
            "[[-0.04691904]\n",
            " [ 0.30006337]\n",
            " [ 2.1291168 ]\n",
            " [ 3.2606914 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 99 is tf.Tensor([2.5929449], shape=(1,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhDtOv5UOB7x",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ERq9GOKKciho"
      },
      "source": [
        "### Model Prediction on 1st Examples in Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gKGvUWahcihp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb6a4b8b-92ed-4b1b-b00d-3de8ce087b73"
      },
      "source": [
        "for i in range(100):\n",
        "  W,b = fn_train(X_test, y_test, W,b,0.01)\n",
        "  print('W at:',i,'is',W)\n",
        "  print('b at:',i,'is',b)\n",
        "  y_pred=fn_prediction(X_test, W,b)\n",
        "  train_loss=fn_loss(y_test,y_pred)\n",
        "  if i%5==0:\n",
        "    print('training loss at step:',i,'is',train_loss)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W at: 0 is tf.Tensor(\n",
            "[[-0.05277965]\n",
            " [ 0.2941811 ]\n",
            " [ 2.1233158 ]\n",
            " [ 3.2547588 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 0 is tf.Tensor([2.581206], shape=(1,), dtype=float32)\n",
            "training loss at step: 0 is tf.Tensor(236848.78, shape=(), dtype=float32)\n",
            "W at: 1 is tf.Tensor(\n",
            "[[-0.05840583]\n",
            " [ 0.2885341 ]\n",
            " [ 2.117747  ]\n",
            " [ 3.2490637 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 1 is tf.Tensor([2.5699368], shape=(1,), dtype=float32)\n",
            "W at: 2 is tf.Tensor(\n",
            "[[-0.06380696]\n",
            " [ 0.28311297]\n",
            " [ 2.112401  ]\n",
            " [ 3.2435963 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 2 is tf.Tensor([2.5591183], shape=(1,), dtype=float32)\n",
            "W at: 3 is tf.Tensor(\n",
            "[[-0.06899203]\n",
            " [ 0.27790868]\n",
            " [ 2.1072688 ]\n",
            " [ 3.2383475 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 3 is tf.Tensor([2.5487325], shape=(1,), dtype=float32)\n",
            "W at: 4 is tf.Tensor(\n",
            "[[-0.0739697 ]\n",
            " [ 0.27291256]\n",
            " [ 2.102342  ]\n",
            " [ 3.2333088 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 4 is tf.Tensor([2.538762], shape=(1,), dtype=float32)\n",
            "W at: 5 is tf.Tensor(\n",
            "[[-0.07874825]\n",
            " [ 0.26811627]\n",
            " [ 2.097612  ]\n",
            " [ 3.2284715 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 5 is tf.Tensor([2.5291905], shape=(1,), dtype=float32)\n",
            "training loss at step: 5 is tf.Tensor(228114.7, shape=(), dtype=float32)\n",
            "W at: 6 is tf.Tensor(\n",
            "[[-0.08333565]\n",
            " [ 0.2635118 ]\n",
            " [ 2.0930712 ]\n",
            " [ 3.2238278 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 6 is tf.Tensor([2.520002], shape=(1,), dtype=float32)\n",
            "W at: 7 is tf.Tensor(\n",
            "[[-0.08773954]\n",
            " [ 0.25909153]\n",
            " [ 2.0887122 ]\n",
            " [ 3.21937   ]], shape=(4, 1), dtype=float32)\n",
            "b at: 7 is tf.Tensor([2.5111806], shape=(1,), dtype=float32)\n",
            "W at: 8 is tf.Tensor(\n",
            "[[-0.09196728]\n",
            " [ 0.25484803]\n",
            " [ 2.0845275 ]\n",
            " [ 3.21509   ]], shape=(4, 1), dtype=float32)\n",
            "b at: 8 is tf.Tensor([2.5027122], shape=(1,), dtype=float32)\n",
            "W at: 9 is tf.Tensor(\n",
            "[[-0.09602589]\n",
            " [ 0.25077426]\n",
            " [ 2.0805101 ]\n",
            " [ 3.2109814 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 9 is tf.Tensor([2.4945827], shape=(1,), dtype=float32)\n",
            "W at: 10 is tf.Tensor(\n",
            "[[-0.09992215]\n",
            " [ 0.24686344]\n",
            " [ 2.0766535 ]\n",
            " [ 3.2070372 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 10 is tf.Tensor([2.4867783], shape=(1,), dtype=float32)\n",
            "training loss at step: 10 is tf.Tensor(221114.69, shape=(), dtype=float32)\n",
            "W at: 11 is tf.Tensor(\n",
            "[[-0.10366255]\n",
            " [ 0.24310905]\n",
            " [ 2.072951  ]\n",
            " [ 3.2032506 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 11 is tf.Tensor([2.479286], shape=(1,), dtype=float32)\n",
            "W at: 12 is tf.Tensor(\n",
            "[[-0.10725333]\n",
            " [ 0.23950481]\n",
            " [ 2.0693967 ]\n",
            " [ 3.1996155 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 12 is tf.Tensor([2.4720933], shape=(1,), dtype=float32)\n",
            "W at: 13 is tf.Tensor(\n",
            "[[-0.11070046]\n",
            " [ 0.23604475]\n",
            " [ 2.0659847 ]\n",
            " [ 3.1961257 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 13 is tf.Tensor([2.4651885], shape=(1,), dtype=float32)\n",
            "W at: 14 is tf.Tensor(\n",
            "[[-0.11400969]\n",
            " [ 0.23272307]\n",
            " [ 2.062709  ]\n",
            " [ 3.1927757 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 14 is tf.Tensor([2.4585598], shape=(1,), dtype=float32)\n",
            "W at: 15 is tf.Tensor(\n",
            "[[-0.11718655]\n",
            " [ 0.22953425]\n",
            " [ 2.0595646 ]\n",
            " [ 3.1895597 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 15 is tf.Tensor([2.4521961], shape=(1,), dtype=float32)\n",
            "training loss at step: 15 is tf.Tensor(215487.88, shape=(), dtype=float32)\n",
            "W at: 16 is tf.Tensor(\n",
            "[[-0.12023633]\n",
            " [ 0.22647297]\n",
            " [ 2.0565457 ]\n",
            " [ 3.1864722 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 16 is tf.Tensor([2.4460871], shape=(1,), dtype=float32)\n",
            "W at: 17 is tf.Tensor(\n",
            "[[-0.1231641 ]\n",
            " [ 0.22353414]\n",
            " [ 2.0536478 ]\n",
            " [ 3.1835082 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 17 is tf.Tensor([2.4402225], shape=(1,), dtype=float32)\n",
            "W at: 18 is tf.Tensor(\n",
            "[[-0.12597476]\n",
            " [ 0.22071286]\n",
            " [ 2.0508657 ]\n",
            " [ 3.1806626 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 18 is tf.Tensor([2.4345925], shape=(1,), dtype=float32)\n",
            "W at: 19 is tf.Tensor(\n",
            "[[-0.12867297]\n",
            " [ 0.2180044 ]\n",
            " [ 2.048195  ]\n",
            " [ 3.177931  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 19 is tf.Tensor([2.4291875], shape=(1,), dtype=float32)\n",
            "W at: 20 is tf.Tensor(\n",
            "[[-0.13126326]\n",
            " [ 0.21540429]\n",
            " [ 2.045631  ]\n",
            " [ 3.1753087 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 20 is tf.Tensor([2.4239988], shape=(1,), dtype=float32)\n",
            "training loss at step: 20 is tf.Tensor(210953.61, shape=(), dtype=float32)\n",
            "W at: 21 is tf.Tensor(\n",
            "[[-0.13374992]\n",
            " [ 0.21290816]\n",
            " [ 2.0431695 ]\n",
            " [ 3.1727912 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 21 is tf.Tensor([2.4190178], shape=(1,), dtype=float32)\n",
            "W at: 22 is tf.Tensor(\n",
            "[[-0.1361371 ]\n",
            " [ 0.21051188]\n",
            " [ 2.0408065 ]\n",
            " [ 3.1703744 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 22 is tf.Tensor([2.4142358], shape=(1,), dtype=float32)\n",
            "W at: 23 is tf.Tensor(\n",
            "[[-0.13842878]\n",
            " [ 0.20821144]\n",
            " [ 2.038538  ]\n",
            " [ 3.1680543 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 23 is tf.Tensor([2.409645], shape=(1,), dtype=float32)\n",
            "W at: 24 is tf.Tensor(\n",
            "[[-0.14062878]\n",
            " [ 0.20600301]\n",
            " [ 2.0363603 ]\n",
            " [ 3.165827  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 24 is tf.Tensor([2.4052382], shape=(1,), dtype=float32)\n",
            "W at: 25 is tf.Tensor(\n",
            "[[-0.14274079]\n",
            " [ 0.2038829 ]\n",
            " [ 2.0342696 ]\n",
            " [ 3.1636887 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 25 is tf.Tensor([2.4010074], shape=(1,), dtype=float32)\n",
            "training loss at step: 25 is tf.Tensor(207292.19, shape=(), dtype=float32)\n",
            "W at: 26 is tf.Tensor(\n",
            "[[-0.1447683]\n",
            " [ 0.2018476]\n",
            " [ 2.0322626]\n",
            " [ 3.1616359]], shape=(4, 1), dtype=float32)\n",
            "b at: 26 is tf.Tensor([2.396946], shape=(1,), dtype=float32)\n",
            "W at: 27 is tf.Tensor(\n",
            "[[-0.14671469]\n",
            " [ 0.1998937 ]\n",
            " [ 2.030336  ]\n",
            " [ 3.159665  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 27 is tf.Tensor([2.3930469], shape=(1,), dtype=float32)\n",
            "W at: 28 is tf.Tensor(\n",
            "[[-0.14858322]\n",
            " [ 0.19801794]\n",
            " [ 2.0284863 ]\n",
            " [ 3.1577733 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 28 is tf.Tensor([2.3893037], shape=(1,), dtype=float32)\n",
            "W at: 29 is tf.Tensor(\n",
            "[[-0.15037699]\n",
            " [ 0.19621721]\n",
            " [ 2.0267105 ]\n",
            " [ 3.155957  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 29 is tf.Tensor([2.3857102], shape=(1,), dtype=float32)\n",
            "W at: 30 is tf.Tensor(\n",
            "[[-0.152099 ]\n",
            " [ 0.1944885]\n",
            " [ 2.0250058]\n",
            " [ 3.1542134]], shape=(4, 1), dtype=float32)\n",
            "b at: 30 is tf.Tensor([2.3822606], shape=(1,), dtype=float32)\n",
            "training loss at step: 30 is tf.Tensor(204330.5, shape=(), dtype=float32)\n",
            "W at: 31 is tf.Tensor(\n",
            "[[-0.15375212]\n",
            " [ 0.19282892]\n",
            " [ 2.0233693 ]\n",
            " [ 3.1525395 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 31 is tf.Tensor([2.378949], shape=(1,), dtype=float32)\n",
            "W at: 32 is tf.Tensor(\n",
            "[[-0.1553391 ]\n",
            " [ 0.19123574]\n",
            " [ 2.0217984 ]\n",
            " [ 3.1509326 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 32 is tf.Tensor([2.3757696], shape=(1,), dtype=float32)\n",
            "W at: 33 is tf.Tensor(\n",
            "[[-0.1568626 ]\n",
            " [ 0.18970627]\n",
            " [ 2.0202904 ]\n",
            " [ 3.14939   ]], shape=(4, 1), dtype=float32)\n",
            "b at: 33 is tf.Tensor([2.3727176], shape=(1,), dtype=float32)\n",
            "W at: 34 is tf.Tensor(\n",
            "[[-0.15832514]\n",
            " [ 0.18823797]\n",
            " [ 2.0188427 ]\n",
            " [ 3.147909  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 34 is tf.Tensor([2.3697877], shape=(1,), dtype=float32)\n",
            "W at: 35 is tf.Tensor(\n",
            "[[-0.15972917]\n",
            " [ 0.18682839]\n",
            " [ 2.0174527 ]\n",
            " [ 3.1464872 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 35 is tf.Tensor([2.3669748], shape=(1,), dtype=float32)\n",
            "training loss at step: 35 is tf.Tensor(201931.44, shape=(), dtype=float32)\n",
            "W at: 36 is tf.Tensor(\n",
            "[[-0.16107702]\n",
            " [ 0.18547519]\n",
            " [ 2.0161185 ]\n",
            " [ 3.1451223 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 36 is tf.Tensor([2.3642745], shape=(1,), dtype=float32)\n",
            "W at: 37 is tf.Tensor(\n",
            "[[-0.16237095]\n",
            " [ 0.1841761 ]\n",
            " [ 2.0148377 ]\n",
            " [ 3.143812  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 37 is tf.Tensor([2.3616822], shape=(1,), dtype=float32)\n",
            "W at: 38 is tf.Tensor(\n",
            "[[-0.16361311]\n",
            " [ 0.18292898]\n",
            " [ 2.013608  ]\n",
            " [ 3.142554  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 38 is tf.Tensor([2.3591936], shape=(1,), dtype=float32)\n",
            "W at: 39 is tf.Tensor(\n",
            "[[-0.16480558]\n",
            " [ 0.18173173]\n",
            " [ 2.0124276 ]\n",
            " [ 3.1413465 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 39 is tf.Tensor([2.3568046], shape=(1,), dtype=float32)\n",
            "W at: 40 is tf.Tensor(\n",
            "[[-0.16595033]\n",
            " [ 0.18058237]\n",
            " [ 2.0112944 ]\n",
            " [ 3.1401873 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 40 is tf.Tensor([2.3545113], shape=(1,), dtype=float32)\n",
            "training loss at step: 40 is tf.Tensor(199985.75, shape=(), dtype=float32)\n",
            "W at: 41 is tf.Tensor(\n",
            "[[-0.16704927]\n",
            " [ 0.17947897]\n",
            " [ 2.0102065 ]\n",
            " [ 3.1390743 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 41 is tf.Tensor([2.3523095], shape=(1,), dtype=float32)\n",
            "W at: 42 is tf.Tensor(\n",
            "[[-0.16810425]\n",
            " [ 0.17841971]\n",
            " [ 2.0091622 ]\n",
            " [ 3.138006  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 42 is tf.Tensor([2.350196], shape=(1,), dtype=float32)\n",
            "W at: 43 is tf.Tensor(\n",
            "[[-0.16911702]\n",
            " [ 0.17740281]\n",
            " [ 2.0081596 ]\n",
            " [ 3.1369803 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 43 is tf.Tensor([2.3481667], shape=(1,), dtype=float32)\n",
            "W at: 44 is tf.Tensor(\n",
            "[[-0.17008926]\n",
            " [ 0.17642657]\n",
            " [ 2.0071971 ]\n",
            " [ 3.1359956 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 44 is tf.Tensor([2.3462188], shape=(1,), dtype=float32)\n",
            "W at: 45 is tf.Tensor(\n",
            "[[-0.17102261]\n",
            " [ 0.17548938]\n",
            " [ 2.006273  ]\n",
            " [ 3.1350503 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 45 is tf.Tensor([2.3443487], shape=(1,), dtype=float32)\n",
            "training loss at step: 45 is tf.Tensor(198406.3, shape=(), dtype=float32)\n",
            "W at: 46 is tf.Tensor(\n",
            "[[-0.1719186 ]\n",
            " [ 0.17458966]\n",
            " [ 2.005386  ]\n",
            " [ 3.1341429 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 46 is tf.Tensor([2.3425534], shape=(1,), dtype=float32)\n",
            "W at: 47 is tf.Tensor(\n",
            "[[-0.17277874]\n",
            " [ 0.17372593]\n",
            " [ 2.0045345 ]\n",
            " [ 3.1332717 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 47 is tf.Tensor([2.3408298], shape=(1,), dtype=float32)\n",
            "W at: 48 is tf.Tensor(\n",
            "[[-0.17360447]\n",
            " [ 0.17289674]\n",
            " [ 2.003717  ]\n",
            " [ 3.1324353 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 48 is tf.Tensor([2.3391755], shape=(1,), dtype=float32)\n",
            "W at: 49 is tf.Tensor(\n",
            "[[-0.17439716]\n",
            " [ 0.17210072]\n",
            " [ 2.002932  ]\n",
            " [ 3.1316323 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 49 is tf.Tensor([2.337587], shape=(1,), dtype=float32)\n",
            "W at: 50 is tf.Tensor(\n",
            "[[-0.17515813]\n",
            " [ 0.17133653]\n",
            " [ 2.0021787 ]\n",
            " [ 3.1308615 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 50 is tf.Tensor([2.3360624], shape=(1,), dtype=float32)\n",
            "training loss at step: 50 is tf.Tensor(197123.1, shape=(), dtype=float32)\n",
            "W at: 51 is tf.Tensor(\n",
            "[[-0.17588864]\n",
            " [ 0.1706029 ]\n",
            " [ 2.0014555 ]\n",
            " [ 3.1301215 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 51 is tf.Tensor([2.3345985], shape=(1,), dtype=float32)\n",
            "W at: 52 is tf.Tensor(\n",
            "[[-0.17658992]\n",
            " [ 0.16989861]\n",
            " [ 2.0007613 ]\n",
            " [ 3.129411  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 52 is tf.Tensor([2.3331933], shape=(1,), dtype=float32)\n",
            "W at: 53 is tf.Tensor(\n",
            "[[-0.17726314]\n",
            " [ 0.16922249]\n",
            " [ 2.0000947 ]\n",
            " [ 3.1287289 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 53 is tf.Tensor([2.3318443], shape=(1,), dtype=float32)\n",
            "W at: 54 is tf.Tensor(\n",
            "[[-0.17790942]\n",
            " [ 0.1685734 ]\n",
            " [ 1.9994547 ]\n",
            " [ 3.1280742 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 54 is tf.Tensor([2.3305492], shape=(1,), dtype=float32)\n",
            "W at: 55 is tf.Tensor(\n",
            "[[-0.17852983]\n",
            " [ 0.16795026]\n",
            " [ 1.9988405 ]\n",
            " [ 3.1274457 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 55 is tf.Tensor([2.329306], shape=(1,), dtype=float32)\n",
            "training loss at step: 55 is tf.Tensor(196079.84, shape=(), dtype=float32)\n",
            "W at: 56 is tf.Tensor(\n",
            "[[-0.17912541]\n",
            " [ 0.16735205]\n",
            " [ 1.9982507 ]\n",
            " [ 3.1268423 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 56 is tf.Tensor([2.3281124], shape=(1,), dtype=float32)\n",
            "W at: 57 is tf.Tensor(\n",
            "[[-0.17969717]\n",
            " [ 0.16677776]\n",
            " [ 1.9976846 ]\n",
            " [ 3.126263  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 57 is tf.Tensor([2.3269665], shape=(1,), dtype=float32)\n",
            "W at: 58 is tf.Tensor(\n",
            "[[-0.18024604]\n",
            " [ 0.16622643]\n",
            " [ 1.9971411 ]\n",
            " [ 3.1257067 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 58 is tf.Tensor([2.3258665], shape=(1,), dtype=float32)\n",
            "W at: 59 is tf.Tensor(\n",
            "[[-0.18077295]\n",
            " [ 0.16569716]\n",
            " [ 1.9966195 ]\n",
            " [ 3.1251729 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 59 is tf.Tensor([2.3248105], shape=(1,), dtype=float32)\n",
            "W at: 60 is tf.Tensor(\n",
            "[[-0.18127875]\n",
            " [ 0.16518904]\n",
            " [ 1.9961187 ]\n",
            " [ 3.1246603 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 60 is tf.Tensor([2.3237967], shape=(1,), dtype=float32)\n",
            "training loss at step: 60 is tf.Tensor(195231.28, shape=(), dtype=float32)\n",
            "W at: 61 is tf.Tensor(\n",
            "[[-0.18176432]\n",
            " [ 0.16470125]\n",
            " [ 1.9956379 ]\n",
            " [ 3.1241682 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 61 is tf.Tensor([2.3228235], shape=(1,), dtype=float32)\n",
            "W at: 62 is tf.Tensor(\n",
            "[[-0.18223046]\n",
            " [ 0.16423297]\n",
            " [ 1.9951763 ]\n",
            " [ 3.1236959 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 62 is tf.Tensor([2.3218892], shape=(1,), dtype=float32)\n",
            "W at: 63 is tf.Tensor(\n",
            "[[-0.18267792]\n",
            " [ 0.1637834 ]\n",
            " [ 1.9947332 ]\n",
            " [ 3.1232424 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 63 is tf.Tensor([2.3209922], shape=(1,), dtype=float32)\n",
            "W at: 64 is tf.Tensor(\n",
            "[[-0.18310748]\n",
            " [ 0.16335182]\n",
            " [ 1.9943079 ]\n",
            " [ 3.122807  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 64 is tf.Tensor([2.3201313], shape=(1,), dtype=float32)\n",
            "W at: 65 is tf.Tensor(\n",
            "[[-0.18351986]\n",
            " [ 0.16293749]\n",
            " [ 1.9938996 ]\n",
            " [ 3.122389  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 65 is tf.Tensor([2.3193047], shape=(1,), dtype=float32)\n",
            "training loss at step: 65 is tf.Tensor(194540.77, shape=(), dtype=float32)\n",
            "W at: 66 is tf.Tensor(\n",
            "[[-0.18391572]\n",
            " [ 0.16253972]\n",
            " [ 1.9935076 ]\n",
            " [ 3.1219878 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 66 is tf.Tensor([2.3185112], shape=(1,), dtype=float32)\n",
            "W at: 67 is tf.Tensor(\n",
            "[[-0.18429573]\n",
            " [ 0.16215786]\n",
            " [ 1.9931313 ]\n",
            " [ 3.1216025 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 67 is tf.Tensor([2.3177495], shape=(1,), dtype=float32)\n",
            "W at: 68 is tf.Tensor(\n",
            "[[-0.18466052]\n",
            " [ 0.16179127]\n",
            " [ 1.99277   ]\n",
            " [ 3.1212327 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 68 is tf.Tensor([2.3170183], shape=(1,), dtype=float32)\n",
            "W at: 69 is tf.Tensor(\n",
            "[[-0.18501072]\n",
            " [ 0.16143933]\n",
            " [ 1.9924232 ]\n",
            " [ 3.1208777 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 69 is tf.Tensor([2.3163161], shape=(1,), dtype=float32)\n",
            "W at: 70 is tf.Tensor(\n",
            "[[-0.18534689]\n",
            " [ 0.16110146]\n",
            " [ 1.9920902 ]\n",
            " [ 3.1205368 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 70 is tf.Tensor([2.315642], shape=(1,), dtype=float32)\n",
            "training loss at step: 70 is tf.Tensor(193978.64, shape=(), dtype=float32)\n",
            "W at: 71 is tf.Tensor(\n",
            "[[-0.1856696]\n",
            " [ 0.1607771]\n",
            " [ 1.9917706]\n",
            " [ 3.1202095]], shape=(4, 1), dtype=float32)\n",
            "b at: 71 is tf.Tensor([2.314995], shape=(1,), dtype=float32)\n",
            "W at: 72 is tf.Tensor(\n",
            "[[-0.1859794 ]\n",
            " [ 0.16046572]\n",
            " [ 1.9914638 ]\n",
            " [ 3.1198952 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 72 is tf.Tensor([2.314374], shape=(1,), dtype=float32)\n",
            "W at: 73 is tf.Tensor(\n",
            "[[-0.1862768 ]\n",
            " [ 0.16016679]\n",
            " [ 1.9911692 ]\n",
            " [ 3.1195936 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 73 is tf.Tensor([2.3137777], shape=(1,), dtype=float32)\n",
            "W at: 74 is tf.Tensor(\n",
            "[[-0.18656227]\n",
            " [ 0.1598798 ]\n",
            " [ 1.9908864 ]\n",
            " [ 3.119304  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 74 is tf.Tensor([2.3132052], shape=(1,), dtype=float32)\n",
            "W at: 75 is tf.Tensor(\n",
            "[[-0.18683632]\n",
            " [ 0.1596043 ]\n",
            " [ 1.990615  ]\n",
            " [ 3.119026  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 75 is tf.Tensor([2.3126557], shape=(1,), dtype=float32)\n",
            "training loss at step: 75 is tf.Tensor(193520.89, shape=(), dtype=float32)\n",
            "W at: 76 is tf.Tensor(\n",
            "[[-0.1870994]\n",
            " [ 0.1593398]\n",
            " [ 1.9903544]\n",
            " [ 3.1187592]], shape=(4, 1), dtype=float32)\n",
            "b at: 76 is tf.Tensor([2.312128], shape=(1,), dtype=float32)\n",
            "W at: 77 is tf.Tensor(\n",
            "[[-0.18735194]\n",
            " [ 0.15908587]\n",
            " [ 1.9901043 ]\n",
            " [ 3.1185029 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 77 is tf.Tensor([2.3116217], shape=(1,), dtype=float32)\n",
            "W at: 78 is tf.Tensor(\n",
            "[[-0.18759437]\n",
            " [ 0.1588421 ]\n",
            " [ 1.9898642 ]\n",
            " [ 3.1182568 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 78 is tf.Tensor([2.3111355], shape=(1,), dtype=float32)\n",
            "W at: 79 is tf.Tensor(\n",
            "[[-0.18782708]\n",
            " [ 0.15860806]\n",
            " [ 1.9896337 ]\n",
            " [ 3.1180205 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 79 is tf.Tensor([2.3106687], shape=(1,), dtype=float32)\n",
            "W at: 80 is tf.Tensor(\n",
            "[[-0.18805048]\n",
            " [ 0.15838338]\n",
            " [ 1.9894124 ]\n",
            " [ 3.1177938 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 80 is tf.Tensor([2.3102207], shape=(1,), dtype=float32)\n",
            "training loss at step: 80 is tf.Tensor(193148.05, shape=(), dtype=float32)\n",
            "W at: 81 is tf.Tensor(\n",
            "[[-0.18826492]\n",
            " [ 0.15816769]\n",
            " [ 1.9892    ]\n",
            " [ 3.1175761 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 81 is tf.Tensor([2.3097906], shape=(1,), dtype=float32)\n",
            "W at: 82 is tf.Tensor(\n",
            "[[-0.18847078]\n",
            " [ 0.15796061]\n",
            " [ 1.988996  ]\n",
            " [ 3.1173673 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 82 is tf.Tensor([2.3093777], shape=(1,), dtype=float32)\n",
            "W at: 83 is tf.Tensor(\n",
            "[[-0.18866839]\n",
            " [ 0.15776181]\n",
            " [ 1.9888003 ]\n",
            " [ 3.1171668 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 83 is tf.Tensor([2.3089812], shape=(1,), dtype=float32)\n",
            "W at: 84 is tf.Tensor(\n",
            "[[-0.18885808]\n",
            " [ 0.15757096]\n",
            " [ 1.9886123 ]\n",
            " [ 3.116974  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 84 is tf.Tensor([2.3086007], shape=(1,), dtype=float32)\n",
            "W at: 85 is tf.Tensor(\n",
            "[[-0.18904017]\n",
            " [ 0.15738773]\n",
            " [ 1.9884318 ]\n",
            " [ 3.116789  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 85 is tf.Tensor([2.3082354], shape=(1,), dtype=float32)\n",
            "training loss at step: 85 is tf.Tensor(192844.3, shape=(), dtype=float32)\n",
            "W at: 86 is tf.Tensor(\n",
            "[[-0.18921496]\n",
            " [ 0.15721183]\n",
            " [ 1.9882586 ]\n",
            " [ 3.1166115 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 86 is tf.Tensor([2.3078847], shape=(1,), dtype=float32)\n",
            "W at: 87 is tf.Tensor(\n",
            "[[-0.18938275]\n",
            " [ 0.15704295]\n",
            " [ 1.9880923 ]\n",
            " [ 3.116441  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 87 is tf.Tensor([2.307548], shape=(1,), dtype=float32)\n",
            "W at: 88 is tf.Tensor(\n",
            "[[-0.18954381]\n",
            " [ 0.15688083]\n",
            " [ 1.9879327 ]\n",
            " [ 3.1162775 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 88 is tf.Tensor([2.3072248], shape=(1,), dtype=float32)\n",
            "W at: 89 is tf.Tensor(\n",
            "[[-0.18969843]\n",
            " [ 0.15672518]\n",
            " [ 1.9877795 ]\n",
            " [ 3.1161203 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 89 is tf.Tensor([2.3069143], shape=(1,), dtype=float32)\n",
            "W at: 90 is tf.Tensor(\n",
            "[[-0.18984684]\n",
            " [ 0.15657575]\n",
            " [ 1.9876324 ]\n",
            " [ 3.1159694 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 90 is tf.Tensor([2.3066163], shape=(1,), dtype=float32)\n",
            "training loss at step: 90 is tf.Tensor(192596.81, shape=(), dtype=float32)\n",
            "W at: 91 is tf.Tensor(\n",
            "[[-0.18998931]\n",
            " [ 0.1564323 ]\n",
            " [ 1.9874913 ]\n",
            " [ 3.1158247 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 91 is tf.Tensor([2.3063302], shape=(1,), dtype=float32)\n",
            "W at: 92 is tf.Tensor(\n",
            "[[-0.19012606]\n",
            " [ 0.15629458]\n",
            " [ 1.9873557 ]\n",
            " [ 3.1156857 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 92 is tf.Tensor([2.3060555], shape=(1,), dtype=float32)\n",
            "W at: 93 is tf.Tensor(\n",
            "[[-0.19025733]\n",
            " [ 0.15616237]\n",
            " [ 1.9872255 ]\n",
            " [ 3.1155522 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 93 is tf.Tensor([2.305792], shape=(1,), dtype=float32)\n",
            "W at: 94 is tf.Tensor(\n",
            "[[-0.19038333]\n",
            " [ 0.15603544]\n",
            " [ 1.9871006 ]\n",
            " [ 3.115424  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 94 is tf.Tensor([2.3055391], shape=(1,), dtype=float32)\n",
            "W at: 95 is tf.Tensor(\n",
            "[[-0.19050428]\n",
            " [ 0.15591358]\n",
            " [ 1.9869807 ]\n",
            " [ 3.115301  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 95 is tf.Tensor([2.3052962], shape=(1,), dtype=float32)\n",
            "training loss at step: 95 is tf.Tensor(192395.12, shape=(), dtype=float32)\n",
            "W at: 96 is tf.Tensor(\n",
            "[[-0.19062038]\n",
            " [ 0.15579659]\n",
            " [ 1.9868655 ]\n",
            " [ 3.1151829 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 96 is tf.Tensor([2.305063], shape=(1,), dtype=float32)\n",
            "W at: 97 is tf.Tensor(\n",
            "[[-0.19073182]\n",
            " [ 0.15568426]\n",
            " [ 1.986755  ]\n",
            " [ 3.1150694 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 97 is tf.Tensor([2.3048391], shape=(1,), dtype=float32)\n",
            "W at: 98 is tf.Tensor(\n",
            "[[-0.1908388 ]\n",
            " [ 0.15557642]\n",
            " [ 1.9866489 ]\n",
            " [ 3.1149604 ]], shape=(4, 1), dtype=float32)\n",
            "b at: 98 is tf.Tensor([2.3046243], shape=(1,), dtype=float32)\n",
            "W at: 99 is tf.Tensor(\n",
            "[[-0.19094148]\n",
            " [ 0.15547289]\n",
            " [ 1.9865471 ]\n",
            " [ 3.114856  ]], shape=(4, 1), dtype=float32)\n",
            "b at: 99 is tf.Tensor([2.304418], shape=(1,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJRBuqXhOB7_"
      },
      "source": [
        "## Classification using tf.Keras\n",
        "\n",
        "In this exercise, we will build a Deep Neural Network using tf.Keras. We will use Iris Dataset for this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O0g6lorycihf"
      },
      "source": [
        "### Load the given Iris data using pandas (Iris.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6xFvb5sRcihg",
        "colab": {}
      },
      "source": [
        "iris_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/aiml/11_Iris.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SAB--Qdwcihm"
      },
      "source": [
        "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6loCye5Yth4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris=pd.get_dummies(iris_df,columns=[\"Species\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4j6RFYOteRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load dataset\n",
        "\n",
        "X = iris.iloc[:,1:5]\n",
        "Y = iris.iloc[:,5:8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jDHaxNclG4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D95nY5ILcihj"
      },
      "source": [
        "### Splitting the data into feature set and target set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RyMQoLMucihj",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b22qpC5xcihr"
      },
      "source": [
        "###  Building Model in tf.keras\n",
        "\n",
        "Build a Linear Classifier model  <br>\n",
        "1.  Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3<br> \n",
        "2. Apply Softmax on Dense Layer outputs <br>\n",
        "3. Use SGD as Optimizer\n",
        "4. Use categorical_crossentropy as loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hov_UFnUciht",
        "colab": {}
      },
      "source": [
        "\n",
        "\t# create model\n",
        "\tmodel = tf.keras.Sequential()\n",
        "\t#model.add(tf.keras.layers.Dense(8, input_dim=4, activation='relu'))\n",
        "\tmodel.add(tf.keras.layers.Dense(3, input_shape=(4,), activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        " \n",
        "\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T5FdzqIKcihw"
      },
      "source": [
        "### Model Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4qLEdHPscihx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07e4e4b4-e7a1-45db-d6a9-1d95aed6dea5"
      },
      "source": [
        " model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=150, batch_size=10)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 105 samples, validate on 45 samples\n",
            "Epoch 1/150\n",
            "105/105 [==============================] - 0s 2ms/sample - loss: 4.8043 - acc: 0.3048 - val_loss: 3.4033 - val_acc: 0.4222\n",
            "Epoch 2/150\n",
            "105/105 [==============================] - 0s 403us/sample - loss: 3.1935 - acc: 0.4000 - val_loss: 2.7215 - val_acc: 0.2889\n",
            "Epoch 3/150\n",
            "105/105 [==============================] - 0s 406us/sample - loss: 2.4339 - acc: 0.3714 - val_loss: 1.9658 - val_acc: 0.5556\n",
            "Epoch 4/150\n",
            "105/105 [==============================] - 0s 414us/sample - loss: 1.7264 - acc: 0.3524 - val_loss: 1.3395 - val_acc: 0.2889\n",
            "Epoch 5/150\n",
            "105/105 [==============================] - 0s 395us/sample - loss: 1.2049 - acc: 0.3714 - val_loss: 1.1280 - val_acc: 0.2889\n",
            "Epoch 6/150\n",
            "105/105 [==============================] - 0s 381us/sample - loss: 1.0629 - acc: 0.3619 - val_loss: 1.0426 - val_acc: 0.2889\n",
            "Epoch 7/150\n",
            "105/105 [==============================] - 0s 411us/sample - loss: 0.9870 - acc: 0.5429 - val_loss: 0.9843 - val_acc: 0.4222\n",
            "Epoch 8/150\n",
            "105/105 [==============================] - 0s 554us/sample - loss: 0.9337 - acc: 0.5810 - val_loss: 0.9844 - val_acc: 0.5778\n",
            "Epoch 9/150\n",
            "105/105 [==============================] - 0s 406us/sample - loss: 0.9063 - acc: 0.6476 - val_loss: 0.9351 - val_acc: 0.6000\n",
            "Epoch 10/150\n",
            "105/105 [==============================] - 0s 390us/sample - loss: 0.8498 - acc: 0.6952 - val_loss: 0.8465 - val_acc: 0.6000\n",
            "Epoch 11/150\n",
            "105/105 [==============================] - 0s 398us/sample - loss: 0.8053 - acc: 0.7524 - val_loss: 0.8358 - val_acc: 0.6000\n",
            "Epoch 12/150\n",
            "105/105 [==============================] - 0s 396us/sample - loss: 0.7808 - acc: 0.6952 - val_loss: 0.8036 - val_acc: 0.6000\n",
            "Epoch 13/150\n",
            "105/105 [==============================] - 0s 412us/sample - loss: 0.7497 - acc: 0.7048 - val_loss: 0.7392 - val_acc: 0.8667\n",
            "Epoch 14/150\n",
            "105/105 [==============================] - 0s 403us/sample - loss: 0.7180 - acc: 0.7429 - val_loss: 0.7430 - val_acc: 0.6000\n",
            "Epoch 15/150\n",
            "105/105 [==============================] - 0s 417us/sample - loss: 0.6867 - acc: 0.7524 - val_loss: 0.7597 - val_acc: 0.6000\n",
            "Epoch 16/150\n",
            "105/105 [==============================] - 0s 408us/sample - loss: 0.6735 - acc: 0.7143 - val_loss: 0.6902 - val_acc: 0.6000\n",
            "Epoch 17/150\n",
            "105/105 [==============================] - 0s 401us/sample - loss: 0.6549 - acc: 0.7810 - val_loss: 0.6934 - val_acc: 0.6000\n",
            "Epoch 18/150\n",
            "105/105 [==============================] - 0s 398us/sample - loss: 0.6367 - acc: 0.6952 - val_loss: 0.6485 - val_acc: 0.7778\n",
            "Epoch 19/150\n",
            "105/105 [==============================] - 0s 438us/sample - loss: 0.6212 - acc: 0.7238 - val_loss: 0.6299 - val_acc: 0.9333\n",
            "Epoch 20/150\n",
            "105/105 [==============================] - 0s 526us/sample - loss: 0.6128 - acc: 0.8667 - val_loss: 0.6545 - val_acc: 0.6000\n",
            "Epoch 21/150\n",
            "105/105 [==============================] - 0s 419us/sample - loss: 0.5984 - acc: 0.8381 - val_loss: 0.6968 - val_acc: 0.6000\n",
            "Epoch 22/150\n",
            "105/105 [==============================] - 0s 419us/sample - loss: 0.5877 - acc: 0.7143 - val_loss: 0.6025 - val_acc: 0.7778\n",
            "Epoch 23/150\n",
            "105/105 [==============================] - 0s 424us/sample - loss: 0.5778 - acc: 0.8381 - val_loss: 0.6087 - val_acc: 0.6000\n",
            "Epoch 24/150\n",
            "105/105 [==============================] - 0s 465us/sample - loss: 0.5698 - acc: 0.7810 - val_loss: 0.6107 - val_acc: 0.6000\n",
            "Epoch 25/150\n",
            "105/105 [==============================] - 0s 579us/sample - loss: 0.5607 - acc: 0.7333 - val_loss: 0.5884 - val_acc: 0.6222\n",
            "Epoch 26/150\n",
            "105/105 [==============================] - 0s 397us/sample - loss: 0.5546 - acc: 0.8190 - val_loss: 0.6053 - val_acc: 0.6000\n",
            "Epoch 27/150\n",
            "105/105 [==============================] - 0s 395us/sample - loss: 0.5451 - acc: 0.7238 - val_loss: 0.5825 - val_acc: 0.6222\n",
            "Epoch 28/150\n",
            "105/105 [==============================] - 0s 383us/sample - loss: 0.5354 - acc: 0.7810 - val_loss: 0.5639 - val_acc: 0.7111\n",
            "Epoch 29/150\n",
            "105/105 [==============================] - 0s 516us/sample - loss: 0.5227 - acc: 0.7905 - val_loss: 0.5554 - val_acc: 0.7111\n",
            "Epoch 30/150\n",
            "105/105 [==============================] - 0s 382us/sample - loss: 0.5204 - acc: 0.7905 - val_loss: 0.5585 - val_acc: 0.6222\n",
            "Epoch 31/150\n",
            "105/105 [==============================] - 0s 364us/sample - loss: 0.5157 - acc: 0.7714 - val_loss: 0.5355 - val_acc: 0.8889\n",
            "Epoch 32/150\n",
            "105/105 [==============================] - 0s 376us/sample - loss: 0.5038 - acc: 0.9048 - val_loss: 0.5969 - val_acc: 0.6000\n",
            "Epoch 33/150\n",
            "105/105 [==============================] - 0s 366us/sample - loss: 0.5039 - acc: 0.7810 - val_loss: 0.5383 - val_acc: 0.7111\n",
            "Epoch 34/150\n",
            "105/105 [==============================] - 0s 376us/sample - loss: 0.4955 - acc: 0.8571 - val_loss: 0.5305 - val_acc: 0.7111\n",
            "Epoch 35/150\n",
            "105/105 [==============================] - 0s 367us/sample - loss: 0.4882 - acc: 0.8857 - val_loss: 0.5813 - val_acc: 0.6000\n",
            "Epoch 36/150\n",
            "105/105 [==============================] - 0s 394us/sample - loss: 0.4983 - acc: 0.7429 - val_loss: 0.5094 - val_acc: 0.9333\n",
            "Epoch 37/150\n",
            "105/105 [==============================] - 0s 391us/sample - loss: 0.4855 - acc: 0.8762 - val_loss: 0.5140 - val_acc: 0.7778\n",
            "Epoch 38/150\n",
            "105/105 [==============================] - 0s 369us/sample - loss: 0.4830 - acc: 0.8571 - val_loss: 0.4989 - val_acc: 0.9556\n",
            "Epoch 39/150\n",
            "105/105 [==============================] - 0s 404us/sample - loss: 0.4681 - acc: 0.9524 - val_loss: 0.5406 - val_acc: 0.6222\n",
            "Epoch 40/150\n",
            "105/105 [==============================] - 0s 376us/sample - loss: 0.4794 - acc: 0.8476 - val_loss: 0.5687 - val_acc: 0.6000\n",
            "Epoch 41/150\n",
            "105/105 [==============================] - 0s 365us/sample - loss: 0.4720 - acc: 0.7810 - val_loss: 0.5313 - val_acc: 0.6222\n",
            "Epoch 42/150\n",
            "105/105 [==============================] - 0s 375us/sample - loss: 0.4636 - acc: 0.8000 - val_loss: 0.4907 - val_acc: 0.8889\n",
            "Epoch 43/150\n",
            "105/105 [==============================] - 0s 376us/sample - loss: 0.4569 - acc: 0.8952 - val_loss: 0.5124 - val_acc: 0.6444\n",
            "Epoch 44/150\n",
            "105/105 [==============================] - 0s 378us/sample - loss: 0.4570 - acc: 0.8190 - val_loss: 0.4816 - val_acc: 0.9333\n",
            "Epoch 45/150\n",
            "105/105 [==============================] - 0s 377us/sample - loss: 0.4498 - acc: 0.8571 - val_loss: 0.4781 - val_acc: 0.9333\n",
            "Epoch 46/150\n",
            "105/105 [==============================] - 0s 380us/sample - loss: 0.4513 - acc: 0.8952 - val_loss: 0.4813 - val_acc: 0.8000\n",
            "Epoch 47/150\n",
            "105/105 [==============================] - 0s 400us/sample - loss: 0.4438 - acc: 0.9048 - val_loss: 0.5037 - val_acc: 0.6444\n",
            "Epoch 48/150\n",
            "105/105 [==============================] - 0s 374us/sample - loss: 0.4469 - acc: 0.8762 - val_loss: 0.4674 - val_acc: 0.9556\n",
            "Epoch 49/150\n",
            "105/105 [==============================] - 0s 379us/sample - loss: 0.4360 - acc: 0.9238 - val_loss: 0.4814 - val_acc: 0.7111\n",
            "Epoch 50/150\n",
            "105/105 [==============================] - 0s 379us/sample - loss: 0.4341 - acc: 0.9048 - val_loss: 0.4825 - val_acc: 0.7111\n",
            "Epoch 51/150\n",
            "105/105 [==============================] - 0s 393us/sample - loss: 0.4300 - acc: 0.8762 - val_loss: 0.4747 - val_acc: 0.7778\n",
            "Epoch 52/150\n",
            "105/105 [==============================] - 0s 436us/sample - loss: 0.4271 - acc: 0.8952 - val_loss: 0.4786 - val_acc: 0.7111\n",
            "Epoch 53/150\n",
            "105/105 [==============================] - 0s 406us/sample - loss: 0.4394 - acc: 0.8571 - val_loss: 0.4671 - val_acc: 0.8000\n",
            "Epoch 54/150\n",
            "105/105 [==============================] - 0s 403us/sample - loss: 0.4227 - acc: 0.9048 - val_loss: 0.4773 - val_acc: 0.7111\n",
            "Epoch 55/150\n",
            "105/105 [==============================] - 0s 431us/sample - loss: 0.4189 - acc: 0.8952 - val_loss: 0.4723 - val_acc: 0.7111\n",
            "Epoch 56/150\n",
            "105/105 [==============================] - 0s 439us/sample - loss: 0.4190 - acc: 0.8857 - val_loss: 0.4846 - val_acc: 0.6889\n",
            "Epoch 57/150\n",
            "105/105 [==============================] - 0s 408us/sample - loss: 0.4185 - acc: 0.8667 - val_loss: 0.4557 - val_acc: 0.8000\n",
            "Epoch 58/150\n",
            "105/105 [==============================] - 0s 417us/sample - loss: 0.4130 - acc: 0.9048 - val_loss: 0.4561 - val_acc: 0.8000\n",
            "Epoch 59/150\n",
            "105/105 [==============================] - 0s 410us/sample - loss: 0.4068 - acc: 0.9238 - val_loss: 0.4418 - val_acc: 0.9333\n",
            "Epoch 60/150\n",
            "105/105 [==============================] - 0s 401us/sample - loss: 0.4112 - acc: 0.9333 - val_loss: 0.4499 - val_acc: 0.8000\n",
            "Epoch 61/150\n",
            "105/105 [==============================] - 0s 392us/sample - loss: 0.4100 - acc: 0.9143 - val_loss: 0.4567 - val_acc: 0.7556\n",
            "Epoch 62/150\n",
            "105/105 [==============================] - 0s 377us/sample - loss: 0.4072 - acc: 0.9143 - val_loss: 0.4642 - val_acc: 0.7111\n",
            "Epoch 63/150\n",
            "105/105 [==============================] - 0s 378us/sample - loss: 0.4053 - acc: 0.8762 - val_loss: 0.4278 - val_acc: 0.9556\n",
            "Epoch 64/150\n",
            "105/105 [==============================] - 0s 371us/sample - loss: 0.3984 - acc: 0.9238 - val_loss: 0.4253 - val_acc: 0.9333\n",
            "Epoch 65/150\n",
            "105/105 [==============================] - 0s 379us/sample - loss: 0.4041 - acc: 0.9143 - val_loss: 0.4443 - val_acc: 0.8000\n",
            "Epoch 66/150\n",
            "105/105 [==============================] - 0s 381us/sample - loss: 0.3950 - acc: 0.8857 - val_loss: 0.4377 - val_acc: 0.8667\n",
            "Epoch 67/150\n",
            "105/105 [==============================] - 0s 392us/sample - loss: 0.3926 - acc: 0.9048 - val_loss: 0.4339 - val_acc: 0.8667\n",
            "Epoch 68/150\n",
            "105/105 [==============================] - 0s 381us/sample - loss: 0.3956 - acc: 0.9143 - val_loss: 0.4185 - val_acc: 0.9556\n",
            "Epoch 69/150\n",
            "105/105 [==============================] - 0s 386us/sample - loss: 0.3904 - acc: 0.9429 - val_loss: 0.4483 - val_acc: 0.7111\n",
            "Epoch 70/150\n",
            "105/105 [==============================] - 0s 376us/sample - loss: 0.3872 - acc: 0.9048 - val_loss: 0.4236 - val_acc: 0.9333\n",
            "Epoch 71/150\n",
            "105/105 [==============================] - 0s 380us/sample - loss: 0.3833 - acc: 0.9333 - val_loss: 0.4314 - val_acc: 0.8000\n",
            "Epoch 72/150\n",
            "105/105 [==============================] - 0s 487us/sample - loss: 0.3819 - acc: 0.9429 - val_loss: 0.4637 - val_acc: 0.7111\n",
            "Epoch 73/150\n",
            "105/105 [==============================] - 0s 396us/sample - loss: 0.3940 - acc: 0.8857 - val_loss: 0.4190 - val_acc: 0.9111\n",
            "Epoch 74/150\n",
            "105/105 [==============================] - 0s 471us/sample - loss: 0.3818 - acc: 0.9238 - val_loss: 0.4349 - val_acc: 0.8000\n",
            "Epoch 75/150\n",
            "105/105 [==============================] - 0s 394us/sample - loss: 0.3687 - acc: 0.8952 - val_loss: 0.4051 - val_acc: 0.9556\n",
            "Epoch 76/150\n",
            "105/105 [==============================] - 0s 378us/sample - loss: 0.3789 - acc: 0.9524 - val_loss: 0.4294 - val_acc: 0.8000\n",
            "Epoch 77/150\n",
            "105/105 [==============================] - 0s 375us/sample - loss: 0.3732 - acc: 0.9238 - val_loss: 0.4241 - val_acc: 0.8000\n",
            "Epoch 78/150\n",
            "105/105 [==============================] - 0s 405us/sample - loss: 0.3702 - acc: 0.9048 - val_loss: 0.4117 - val_acc: 0.9333\n",
            "Epoch 79/150\n",
            "105/105 [==============================] - 0s 387us/sample - loss: 0.3691 - acc: 0.9333 - val_loss: 0.4094 - val_acc: 0.9333\n",
            "Epoch 80/150\n",
            "105/105 [==============================] - 0s 369us/sample - loss: 0.3693 - acc: 0.9238 - val_loss: 0.3987 - val_acc: 0.9556\n",
            "Epoch 81/150\n",
            "105/105 [==============================] - 0s 391us/sample - loss: 0.3664 - acc: 0.9714 - val_loss: 0.4094 - val_acc: 0.8667\n",
            "Epoch 82/150\n",
            "105/105 [==============================] - 0s 381us/sample - loss: 0.3640 - acc: 0.9429 - val_loss: 0.4130 - val_acc: 0.8667\n",
            "Epoch 83/150\n",
            "105/105 [==============================] - 0s 379us/sample - loss: 0.3679 - acc: 0.9238 - val_loss: 0.4089 - val_acc: 0.8667\n",
            "Epoch 84/150\n",
            "105/105 [==============================] - 0s 368us/sample - loss: 0.3617 - acc: 0.9238 - val_loss: 0.4078 - val_acc: 0.8667\n",
            "Epoch 85/150\n",
            "105/105 [==============================] - 0s 384us/sample - loss: 0.3582 - acc: 0.9524 - val_loss: 0.4023 - val_acc: 0.9111\n",
            "Epoch 86/150\n",
            "105/105 [==============================] - 0s 358us/sample - loss: 0.3594 - acc: 0.9429 - val_loss: 0.4101 - val_acc: 0.8667\n",
            "Epoch 87/150\n",
            "105/105 [==============================] - 0s 378us/sample - loss: 0.3654 - acc: 0.9524 - val_loss: 0.3890 - val_acc: 0.9556\n",
            "Epoch 88/150\n",
            "105/105 [==============================] - 0s 364us/sample - loss: 0.3538 - acc: 0.9524 - val_loss: 0.4062 - val_acc: 0.8667\n",
            "Epoch 89/150\n",
            "105/105 [==============================] - 0s 344us/sample - loss: 0.3505 - acc: 0.9619 - val_loss: 0.3959 - val_acc: 0.9333\n",
            "Epoch 90/150\n",
            "105/105 [==============================] - 0s 351us/sample - loss: 0.3510 - acc: 0.9238 - val_loss: 0.4207 - val_acc: 0.7556\n",
            "Epoch 91/150\n",
            "105/105 [==============================] - 0s 343us/sample - loss: 0.3545 - acc: 0.9238 - val_loss: 0.4029 - val_acc: 0.8667\n",
            "Epoch 92/150\n",
            "105/105 [==============================] - 0s 348us/sample - loss: 0.3477 - acc: 0.9238 - val_loss: 0.3955 - val_acc: 0.8667\n",
            "Epoch 93/150\n",
            "105/105 [==============================] - 0s 348us/sample - loss: 0.3473 - acc: 0.9143 - val_loss: 0.3824 - val_acc: 0.9556\n",
            "Epoch 94/150\n",
            "105/105 [==============================] - 0s 352us/sample - loss: 0.3527 - acc: 0.9619 - val_loss: 0.3930 - val_acc: 0.8667\n",
            "Epoch 95/150\n",
            "105/105 [==============================] - 0s 366us/sample - loss: 0.3492 - acc: 0.9524 - val_loss: 0.4084 - val_acc: 0.8000\n",
            "Epoch 96/150\n",
            "105/105 [==============================] - 0s 353us/sample - loss: 0.3442 - acc: 0.9333 - val_loss: 0.3841 - val_acc: 0.9333\n",
            "Epoch 97/150\n",
            "105/105 [==============================] - 0s 460us/sample - loss: 0.3414 - acc: 0.9714 - val_loss: 0.3838 - val_acc: 0.9333\n",
            "Epoch 98/150\n",
            "105/105 [==============================] - 0s 362us/sample - loss: 0.3380 - acc: 0.9714 - val_loss: 0.4007 - val_acc: 0.8000\n",
            "Epoch 99/150\n",
            "105/105 [==============================] - 0s 350us/sample - loss: 0.3373 - acc: 0.9333 - val_loss: 0.3816 - val_acc: 0.9333\n",
            "Epoch 100/150\n",
            "105/105 [==============================] - 0s 355us/sample - loss: 0.3369 - acc: 0.9619 - val_loss: 0.3818 - val_acc: 0.9333\n",
            "Epoch 101/150\n",
            "105/105 [==============================] - 0s 347us/sample - loss: 0.3332 - acc: 0.9810 - val_loss: 0.4258 - val_acc: 0.7111\n",
            "Epoch 102/150\n",
            "105/105 [==============================] - 0s 353us/sample - loss: 0.3361 - acc: 0.9143 - val_loss: 0.3864 - val_acc: 0.8667\n",
            "Epoch 103/150\n",
            "105/105 [==============================] - 0s 355us/sample - loss: 0.3361 - acc: 0.9524 - val_loss: 0.3775 - val_acc: 0.9333\n",
            "Epoch 104/150\n",
            "105/105 [==============================] - 0s 350us/sample - loss: 0.3336 - acc: 0.9429 - val_loss: 0.3828 - val_acc: 0.8667\n",
            "Epoch 105/150\n",
            "105/105 [==============================] - 0s 380us/sample - loss: 0.3325 - acc: 0.9429 - val_loss: 0.3684 - val_acc: 0.9556\n",
            "Epoch 106/150\n",
            "105/105 [==============================] - 0s 350us/sample - loss: 0.3324 - acc: 0.9714 - val_loss: 0.3897 - val_acc: 0.8667\n",
            "Epoch 107/150\n",
            "105/105 [==============================] - 0s 344us/sample - loss: 0.3281 - acc: 0.9619 - val_loss: 0.3839 - val_acc: 0.8667\n",
            "Epoch 108/150\n",
            "105/105 [==============================] - 0s 359us/sample - loss: 0.3302 - acc: 0.9524 - val_loss: 0.3798 - val_acc: 0.8667\n",
            "Epoch 109/150\n",
            "105/105 [==============================] - 0s 348us/sample - loss: 0.3239 - acc: 0.9714 - val_loss: 0.3987 - val_acc: 0.8000\n",
            "Epoch 110/150\n",
            "105/105 [==============================] - 0s 347us/sample - loss: 0.3230 - acc: 0.9238 - val_loss: 0.3775 - val_acc: 0.8667\n",
            "Epoch 111/150\n",
            "105/105 [==============================] - 0s 371us/sample - loss: 0.3274 - acc: 0.9429 - val_loss: 0.3834 - val_acc: 0.8667\n",
            "Epoch 112/150\n",
            "105/105 [==============================] - 0s 354us/sample - loss: 0.3255 - acc: 0.9524 - val_loss: 0.3767 - val_acc: 0.8667\n",
            "Epoch 113/150\n",
            "105/105 [==============================] - 0s 375us/sample - loss: 0.3192 - acc: 0.9429 - val_loss: 0.3586 - val_acc: 0.9556\n",
            "Epoch 114/150\n",
            "105/105 [==============================] - 0s 341us/sample - loss: 0.3195 - acc: 0.9714 - val_loss: 0.3919 - val_acc: 0.8000\n",
            "Epoch 115/150\n",
            "105/105 [==============================] - 0s 358us/sample - loss: 0.3184 - acc: 0.9333 - val_loss: 0.3977 - val_acc: 0.7778\n",
            "Epoch 116/150\n",
            "105/105 [==============================] - 0s 347us/sample - loss: 0.3197 - acc: 0.9333 - val_loss: 0.3538 - val_acc: 0.9556\n",
            "Epoch 117/150\n",
            "105/105 [==============================] - 0s 344us/sample - loss: 0.3146 - acc: 0.9714 - val_loss: 0.3625 - val_acc: 0.9333\n",
            "Epoch 118/150\n",
            "105/105 [==============================] - 0s 367us/sample - loss: 0.3156 - acc: 0.9619 - val_loss: 0.3577 - val_acc: 0.9556\n",
            "Epoch 119/150\n",
            "105/105 [==============================] - 0s 351us/sample - loss: 0.3115 - acc: 0.9524 - val_loss: 0.3483 - val_acc: 0.9778\n",
            "Epoch 120/150\n",
            "105/105 [==============================] - 0s 380us/sample - loss: 0.3148 - acc: 0.9714 - val_loss: 0.3547 - val_acc: 0.9556\n",
            "Epoch 121/150\n",
            "105/105 [==============================] - 0s 477us/sample - loss: 0.3110 - acc: 0.9619 - val_loss: 0.3461 - val_acc: 0.9778\n",
            "Epoch 122/150\n",
            "105/105 [==============================] - 0s 363us/sample - loss: 0.3114 - acc: 0.9810 - val_loss: 0.3486 - val_acc: 0.9556\n",
            "Epoch 123/150\n",
            "105/105 [==============================] - 0s 346us/sample - loss: 0.3099 - acc: 0.9524 - val_loss: 0.3449 - val_acc: 0.9778\n",
            "Epoch 124/150\n",
            "105/105 [==============================] - 0s 348us/sample - loss: 0.3110 - acc: 0.9619 - val_loss: 0.3833 - val_acc: 0.8000\n",
            "Epoch 125/150\n",
            "105/105 [==============================] - 0s 351us/sample - loss: 0.3079 - acc: 0.9429 - val_loss: 0.3457 - val_acc: 0.9556\n",
            "Epoch 126/150\n",
            "105/105 [==============================] - 0s 366us/sample - loss: 0.3077 - acc: 0.9810 - val_loss: 0.3538 - val_acc: 0.9556\n",
            "Epoch 127/150\n",
            "105/105 [==============================] - 0s 360us/sample - loss: 0.3080 - acc: 0.9333 - val_loss: 0.3521 - val_acc: 0.9556\n",
            "Epoch 128/150\n",
            "105/105 [==============================] - 0s 358us/sample - loss: 0.3043 - acc: 0.9429 - val_loss: 0.3470 - val_acc: 0.9556\n",
            "Epoch 129/150\n",
            "105/105 [==============================] - 0s 364us/sample - loss: 0.3032 - acc: 0.9714 - val_loss: 0.3817 - val_acc: 0.8000\n",
            "Epoch 130/150\n",
            "105/105 [==============================] - 0s 346us/sample - loss: 0.3058 - acc: 0.9333 - val_loss: 0.3535 - val_acc: 0.9333\n",
            "Epoch 131/150\n",
            "105/105 [==============================] - 0s 363us/sample - loss: 0.3049 - acc: 0.9619 - val_loss: 0.3505 - val_acc: 0.9333\n",
            "Epoch 132/150\n",
            "105/105 [==============================] - 0s 356us/sample - loss: 0.3013 - acc: 0.9714 - val_loss: 0.3539 - val_acc: 0.9333\n",
            "Epoch 133/150\n",
            "105/105 [==============================] - 0s 343us/sample - loss: 0.3030 - acc: 0.9238 - val_loss: 0.3658 - val_acc: 0.8667\n",
            "Epoch 134/150\n",
            "105/105 [==============================] - 0s 361us/sample - loss: 0.3011 - acc: 0.9619 - val_loss: 0.3490 - val_acc: 0.9333\n",
            "Epoch 135/150\n",
            "105/105 [==============================] - 0s 353us/sample - loss: 0.2959 - acc: 0.9714 - val_loss: 0.3593 - val_acc: 0.8667\n",
            "Epoch 136/150\n",
            "105/105 [==============================] - 0s 353us/sample - loss: 0.2982 - acc: 0.9429 - val_loss: 0.3321 - val_acc: 0.9778\n",
            "Epoch 137/150\n",
            "105/105 [==============================] - 0s 350us/sample - loss: 0.2981 - acc: 0.9810 - val_loss: 0.3365 - val_acc: 0.9556\n",
            "Epoch 138/150\n",
            "105/105 [==============================] - 0s 370us/sample - loss: 0.2933 - acc: 0.9619 - val_loss: 0.3309 - val_acc: 0.9778\n",
            "Epoch 139/150\n",
            "105/105 [==============================] - 0s 355us/sample - loss: 0.2973 - acc: 0.9619 - val_loss: 0.3391 - val_acc: 0.9556\n",
            "Epoch 140/150\n",
            "105/105 [==============================] - 0s 362us/sample - loss: 0.2912 - acc: 0.9429 - val_loss: 0.3327 - val_acc: 0.9556\n",
            "Epoch 141/150\n",
            "105/105 [==============================] - 0s 357us/sample - loss: 0.2904 - acc: 0.9619 - val_loss: 0.3284 - val_acc: 0.9778\n",
            "Epoch 142/150\n",
            "105/105 [==============================] - 0s 356us/sample - loss: 0.2948 - acc: 0.9714 - val_loss: 0.3422 - val_acc: 0.9333\n",
            "Epoch 143/150\n",
            "105/105 [==============================] - 0s 347us/sample - loss: 0.2901 - acc: 0.9619 - val_loss: 0.3374 - val_acc: 0.9556\n",
            "Epoch 144/150\n",
            "105/105 [==============================] - 0s 368us/sample - loss: 0.2875 - acc: 0.9714 - val_loss: 0.3266 - val_acc: 0.9556\n",
            "Epoch 145/150\n",
            "105/105 [==============================] - 0s 480us/sample - loss: 0.2893 - acc: 0.9619 - val_loss: 0.3640 - val_acc: 0.8444\n",
            "Epoch 146/150\n",
            "105/105 [==============================] - 0s 369us/sample - loss: 0.2932 - acc: 0.9333 - val_loss: 0.3618 - val_acc: 0.8444\n",
            "Epoch 147/150\n",
            "105/105 [==============================] - 0s 356us/sample - loss: 0.2891 - acc: 0.9524 - val_loss: 0.3337 - val_acc: 0.9556\n",
            "Epoch 148/150\n",
            "105/105 [==============================] - 0s 349us/sample - loss: 0.2834 - acc: 0.9714 - val_loss: 0.3341 - val_acc: 0.9556\n",
            "Epoch 149/150\n",
            "105/105 [==============================] - 0s 354us/sample - loss: 0.2852 - acc: 0.9714 - val_loss: 0.3560 - val_acc: 0.8667\n",
            "Epoch 150/150\n",
            "105/105 [==============================] - 0s 336us/sample - loss: 0.2904 - acc: 0.9619 - val_loss: 0.3513 - val_acc: 0.8667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f81369aeda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y-SgSSdRcih5"
      },
      "source": [
        "### Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GBgKZkhkcih6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c3726a8f-3230-4f67-de71-7ceca382174c"
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "scores[1]*100"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 0s 1ms/sample - loss: 0.3513 - acc: 0.8667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86.66666746139526"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fXBxH5ivnUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_pred= model.predict_classes(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P32ASP1Vjt0a"
      },
      "source": [
        "### Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8rd0jjAjyTR",
        "colab": {}
      },
      "source": [
        "model.save('Keras_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XiipRpe7rbVh"
      },
      "source": [
        "### Build and Train a Deep Neural network with 2 hidden layer  - Optional - For Practice\n",
        "\n",
        "Does it perform better than Linear Classifier? What could be the reason for difference in performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v5Du3lubr4sA",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}