{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SeqModelNLP_R9_Project1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xT7MKZuMRaCg"
      },
      "source": [
        "# Sentiment Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wq4RCyyPSYRp"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGCtiXUhSWss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "b7cb4db1-caad-4abe-dad7-eaa90921f9ed"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "import numpy as np\n",
        "# save np.load\n",
        "np_load_old = np.load\n",
        "\n",
        "# modify the default parameters of np.load\n",
        "np.load = lambda *a,**k: np_load_old(*a,allow_pickle=True)\n",
        "\n",
        "vocab_size = 10000 #vocab size\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size) # vocab_size is no.of words to consider from the dataset, ordering based on frequency.\n",
        "\n",
        "# restore np.load for future normal usage\n",
        "np.load = np_load_old"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH2boTVR3r8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "115a4bf2-26de-4d20-95a4-5f8082b01c99"
      },
      "source": [
        "\n",
        "x_train.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k62xpg4z3r8X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c560b03c-796f-4963-b447-ab147d5fbc3a"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fCPC_WN-eCyw",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "vocab_size = 10000 #vocab size\n",
        "maxlen = 300  #number of word used from each review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qMEsHYrWxdtk"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h0g381XzeCyz",
        "colab": {}
      },
      "source": [
        "#load dataset as a list of ints\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "#make all sequences of the same length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test =  pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jy6n-uM2eCy2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "251bc931-d326-403a-d209-4cfd9b7cdf28"
      },
      "source": [
        "\n",
        "print(x_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...   19  178   32]\n",
            " [   0    0    0 ...   16  145   95]\n",
            " [   0    0    0 ...    7  129  113]\n",
            " ...\n",
            " [   0    0    0 ...    4 3586    2]\n",
            " [   0    0    0 ...   12    9   23]\n",
            " [   0    0    0 ...  204  131    9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZhMAgaNeCy5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "f6338116-08c1-4148-a483-078baf4c2803"
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...   14    6  717]\n",
            " [   0    0    0 ...  125    4 3077]\n",
            " [1239 5189  137 ...    9   57  975]\n",
            " ...\n",
            " [   0    0    0 ...   21  846 5518]\n",
            " [   0    0    0 ... 2302    7  470]\n",
            " [   0    0    0 ...   34 2005 2643]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dybtUgUReCy8"
      },
      "source": [
        "## Build Keras Embedding Layer Model\n",
        "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
        "\n",
        "* The embedding layer can be used at the start of a larger deep learning model. \n",
        "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
        "* Use the embedding layer to train our own word2vec models.\n",
        "\n",
        "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A5OLM4eBeCy9",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional,SimpleRNN\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TxNDNhrseCzA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe5938ba-a969-4893-d2e0-ecb25e7152f4"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L3CSVVPPeCzD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "312fd4d4-f224-4875-f744-807f47da0738"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OZHw7wD3r8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "6f696033-b71d-434d-87d9-6bb8016b5c8c"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 8, input_length=maxlen))\n",
        "model.add(\n",
        "    SimpleRNN(\n",
        "        1, return_sequences=False, dropout=0.1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "# summarize the model\n",
        "print(model.summary())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 300, 8)            80000     \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, 1)                 10        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 80,012\n",
            "Trainable params: 80,012\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Igq8Qm8GeCzG"
      },
      "source": [
        "## Retrive the output of each layer in keras for a given single test sample from the trained model you built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0AqOnLa2eCzH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ed7afed-19cf-4702-fe6a-56f1f126730c"
      },
      "source": [
        "\n",
        "# fit the model\n",
        "model.fit(x_train, y_train, epochs=50)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "25000/25000 [==============================] - 153s 6ms/step - loss: 0.6008 - acc: 0.7589\n",
            "Epoch 2/50\n",
            "25000/25000 [==============================] - 143s 6ms/step - loss: 0.4931 - acc: 0.8133\n",
            "Epoch 3/50\n",
            "25000/25000 [==============================] - 141s 6ms/step - loss: 0.4257 - acc: 0.8346\n",
            "Epoch 4/50\n",
            "25000/25000 [==============================] - 141s 6ms/step - loss: 0.4107 - acc: 0.8334\n",
            "Epoch 5/50\n",
            "25000/25000 [==============================] - 145s 6ms/step - loss: 0.3725 - acc: 0.8541\n",
            "Epoch 6/50\n",
            "25000/25000 [==============================] - 143s 6ms/step - loss: 0.3581 - acc: 0.8600\n",
            "Epoch 7/50\n",
            "25000/25000 [==============================] - 142s 6ms/step - loss: 0.3461 - acc: 0.8652\n",
            "Epoch 8/50\n",
            "25000/25000 [==============================] - 142s 6ms/step - loss: 0.3359 - acc: 0.8708\n",
            "Epoch 9/50\n",
            "25000/25000 [==============================] - 142s 6ms/step - loss: 0.3223 - acc: 0.8774\n",
            "Epoch 10/50\n",
            "25000/25000 [==============================] - 142s 6ms/step - loss: 0.3442 - acc: 0.8672\n",
            "Epoch 11/50\n",
            "25000/25000 [==============================] - 142s 6ms/step - loss: 0.3254 - acc: 0.8758\n",
            "Epoch 12/50\n",
            "25000/25000 [==============================] - 141s 6ms/step - loss: 0.2972 - acc: 0.8910\n",
            "Epoch 13/50\n",
            "25000/25000 [==============================] - 140s 6ms/step - loss: 0.2872 - acc: 0.8956\n",
            "Epoch 14/50\n",
            "25000/25000 [==============================] - 141s 6ms/step - loss: 0.2795 - acc: 0.8993\n",
            "Epoch 15/50\n",
            "25000/25000 [==============================] - 140s 6ms/step - loss: 0.2745 - acc: 0.9008\n",
            "Epoch 16/50\n",
            "25000/25000 [==============================] - 141s 6ms/step - loss: 0.2653 - acc: 0.9053\n",
            "Epoch 17/50\n",
            "25000/25000 [==============================] - 140s 6ms/step - loss: 0.2577 - acc: 0.9091\n",
            "Epoch 18/50\n",
            "25000/25000 [==============================] - 140s 6ms/step - loss: 0.2864 - acc: 0.8926\n",
            "Epoch 19/50\n",
            "25000/25000 [==============================] - 140s 6ms/step - loss: 0.2545 - acc: 0.9101\n",
            "Epoch 20/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.2428 - acc: 0.9152\n",
            "Epoch 21/50\n",
            "25000/25000 [==============================] - 140s 6ms/step - loss: 0.2368 - acc: 0.9184\n",
            "Epoch 22/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.2403 - acc: 0.9158\n",
            "Epoch 23/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.2300 - acc: 0.9204\n",
            "Epoch 24/50\n",
            "25000/25000 [==============================] - 140s 6ms/step - loss: 0.2455 - acc: 0.9152\n",
            "Epoch 25/50\n",
            "25000/25000 [==============================] - 140s 6ms/step - loss: 0.2226 - acc: 0.9224\n",
            "Epoch 26/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.2351 - acc: 0.9176\n",
            "Epoch 27/50\n",
            "25000/25000 [==============================] - 140s 6ms/step - loss: 0.2239 - acc: 0.9221\n",
            "Epoch 28/50\n",
            "25000/25000 [==============================] - 140s 6ms/step - loss: 0.2111 - acc: 0.9289\n",
            "Epoch 29/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.2046 - acc: 0.9318\n",
            "Epoch 30/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.2072 - acc: 0.9294\n",
            "Epoch 31/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.2189 - acc: 0.9252\n",
            "Epoch 32/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.1987 - acc: 0.9347\n",
            "Epoch 33/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.2003 - acc: 0.9316\n",
            "Epoch 34/50\n",
            "25000/25000 [==============================] - 138s 6ms/step - loss: 0.2006 - acc: 0.9320\n",
            "Epoch 35/50\n",
            "25000/25000 [==============================] - 138s 6ms/step - loss: 0.1949 - acc: 0.9358\n",
            "Epoch 36/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.1923 - acc: 0.9361\n",
            "Epoch 37/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.2002 - acc: 0.9305\n",
            "Epoch 38/50\n",
            "25000/25000 [==============================] - 138s 6ms/step - loss: 0.1943 - acc: 0.9348\n",
            "Epoch 39/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.2000 - acc: 0.9331\n",
            "Epoch 40/50\n",
            "25000/25000 [==============================] - 138s 6ms/step - loss: 0.1831 - acc: 0.9409\n",
            "Epoch 41/50\n",
            "25000/25000 [==============================] - 138s 6ms/step - loss: 0.1813 - acc: 0.9414\n",
            "Epoch 42/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.1738 - acc: 0.9444\n",
            "Epoch 43/50\n",
            "25000/25000 [==============================] - 139s 6ms/step - loss: 0.2145 - acc: 0.9285\n",
            "Epoch 44/50\n",
            "25000/25000 [==============================] - 138s 6ms/step - loss: 0.2002 - acc: 0.9335\n",
            "Epoch 45/50\n",
            "25000/25000 [==============================] - 138s 6ms/step - loss: 0.1789 - acc: 0.9415\n",
            "Epoch 46/50\n",
            "25000/25000 [==============================] - 138s 6ms/step - loss: 0.1740 - acc: 0.9432\n",
            "Epoch 47/50\n",
            "25000/25000 [==============================] - 138s 6ms/step - loss: 0.1955 - acc: 0.9353\n",
            "Epoch 48/50\n",
            "25000/25000 [==============================] - 137s 5ms/step - loss: 0.1998 - acc: 0.9322\n",
            "Epoch 49/50\n",
            "25000/25000 [==============================] - 138s 6ms/step - loss: 0.1810 - acc: 0.9405\n",
            "Epoch 50/50\n",
            "25000/25000 [==============================] - 138s 6ms/step - loss: 0.1720 - acc: 0.9452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2cf25f82e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-dUDSg7VeCzM",
        "colab": {}
      },
      "source": [
        "model.save(\"./SeqNLP_Project1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tskt_1npeCzP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ad8c9924-22ce-480d-c079-1ab0cce93226"
      },
      "source": [
        "\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Accuracy: %f' % (accuracy*100))\n",
        "print('Loss: %f' % (loss))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 86s 3ms/step\n",
            "Accuracy: 76.700000\n",
            "Loss: 0.674408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU6OwO453r9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62e49b6f-ccbf-4eea-fb36-196828331dc8"
      },
      "source": [
        "\n",
        "model.predict(x_test[[0]])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9511795]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diJalLCf3r9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "726535b8-d347-488e-e71d-6766af35c17d"
      },
      "source": [
        "from keras import backend as back\n",
        "\n",
        "inpt = model.input\n",
        "output = [layer.output for layer in model.layers]\n",
        "evalFunction = [back.function([inpt, back.learning_phase()], [out]) for out in output]\n",
        "\n",
        "layerOpt = [func([x_test[[0]], 1.]) for func in evalFunction]\n",
        "print(layerOpt)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[array([[[-0.00515717,  0.06356188,  0.01696332, ...,  0.06018887,\n",
            "          0.05213069,  0.02424783],\n",
            "        [-0.00515717,  0.06356188,  0.01696332, ...,  0.06018887,\n",
            "          0.05213069,  0.02424783],\n",
            "        [-0.00515717,  0.06356188,  0.01696332, ...,  0.06018887,\n",
            "          0.05213069,  0.02424783],\n",
            "        ...,\n",
            "        [ 0.04749067, -0.09079694, -0.07947935, ..., -0.00694379,\n",
            "         -0.03578651, -0.1598345 ],\n",
            "        [ 0.01074871,  0.02934771,  0.03399529, ..., -0.07170125,\n",
            "          0.05007496,  0.02882561],\n",
            "        [ 0.12924863,  0.0158901 , -0.00834902, ...,  0.22296906,\n",
            "          0.02161513,  0.1067538 ]]], dtype=float32)], [array([[0.5340278]], dtype=float32)], [array([[0.96764797]], dtype=float32)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzZqJXjY3r9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "8e47fe22-3072-4afe-a805-c1fc9f0bdc0e"
      },
      "source": [
        "print('Embedding layer Output')\n",
        "layerOpt[0][0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding layer Output\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.00515717,  0.06356188,  0.01696332, ...,  0.06018887,\n",
              "          0.05213069,  0.02424783],\n",
              "        [-0.00515717,  0.06356188,  0.01696332, ...,  0.06018887,\n",
              "          0.05213069,  0.02424783],\n",
              "        [-0.00515717,  0.06356188,  0.01696332, ...,  0.06018887,\n",
              "          0.05213069,  0.02424783],\n",
              "        ...,\n",
              "        [ 0.04749067, -0.09079694, -0.07947935, ..., -0.00694379,\n",
              "         -0.03578651, -0.1598345 ],\n",
              "        [ 0.01074871,  0.02934771,  0.03399529, ..., -0.07170125,\n",
              "          0.05007496,  0.02882561],\n",
              "        [ 0.12924863,  0.0158901 , -0.00834902, ...,  0.22296906,\n",
              "          0.02161513,  0.1067538 ]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANqDR7Af3r9b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c22eb78f-d68a-4ea7-902d-a02416e5df18"
      },
      "source": [
        "print('RNN Output')\n",
        "layerOpt[1]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN Output\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.5340278]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYm_iffF3r9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2b200db9-df0d-4cbc-e19f-d57f34b5440e"
      },
      "source": [
        "print('Dense Layer output')\n",
        "layerOpt[2]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dense Layer output\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.96764797]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}